Generalized Recursive Functions
===============================
Recursive references are legal in any lambda expression.

Recursive references must be contained within lambda expressions,
or an error is reported. Eg, we report an error on `x = x + 1`.

Recursive references are not supported in definitions like `pat = expr`
where `pat` is not an identifier pattern.

In a definition like
    x = expr
where expr contains lambda expressions with recursive references, the functions
computed from those lambda expressions must not be called during the initial
evaluation of the definiens 'expr', before the result of 'expr' is bound to x.
That will produce an error.

Implementation Alternatives:
 * tracing garbage collector
 * reclaiming cyclic structures using reference counting <-- this one
 * thunks

Implementation: Tracing Garbage Collector
-----------------------------------------
* Use a tracing garbage collector (instead of ref counting).
* Frame slots containing recursive variables are represented by thunks.
  The thunk is evaluated on first reference, then the slot is updated with
  the result. If there is a recursive loop during thunk evaluation, throw
  an error.
* This is very expressive. Any recursive definition that makes logical sense
  will work, and with low implementation complexity (other than the GC).
  There are cases where recursive references are outside of lambda expressions,
  but no divergence is possible, and these cases will work.
* Nothing special needs to be done about lambda expressions, or closures,
  or multi-variable patterns. Closures containing recursive references will
  turn into cyclic structures after thunk evaluation, but it doesn't matter.
* Maybe a special opcode is used for recursive references, to implement the
  thunk logic. Thus zero overhead for non-recursive references.

** One big loss: copy-on-write for efficient data structure update.
This requires more complex and less efficient solutions. Unless there is a
hybrid solution where the only cyclic loops involve closure values, and data
structures still have accurate refcounts.

Does this technique allow unprintable cyclic data structures?
I don't want that. Hmm...
    a = [1, a]
If we eagerly evaluate the 'a' reference when evaluating [1,a], then we get a
thunk loop and report an error. So that's okay.

What is the tradeoff between the complexity of a tracing garbage collector,
vs the complexity of the code for making cyclic structures collectable via
reference counting?

One possible downside of a tracing garbage collector is: what happens when I
embed Curv in another programming language (eg, C++, Rust, Python, Lisp)?
If Curv is intended to be like SVG only more powerful, then other languages need
the ability to open *.curv files and interface with Curv modules.
 * There may be a problem with Curv allocating large blocks of memory reserved
   to its own use, with most of the memory being unused, in conflict with the
   running application in which Curv is embedded, which also wants to allocate
   memory. (Lua does this, and is considered highly embeddable. Maybe not a big
   issue due to today's large memory sizes?)
 * Writing native code or host language functions that are called from the
   Curv interpreter could be tricky if Curv has a tracing collector. How does
   Curv's collector get GC roots for objects referenced by native functions?
   The answer is: I can provide exactly the same C++ API (make<T>, Shared<T>)
   that I currently use for creating and holding reference counted objects.

Implementation: Reclaiming Cyclic Structures using Reference Counting
---------------------------------------------------------------------
Suppose that a closure has 2 nonlocal dictionaries. Both are refcounted objects.
 * One contains only nonrecursive references. This dictionary is private
   to a specific closure object.
 * One contains only recursive references. This dictionary is shared by all
   the closures in the recursion group.

And suppose we use the same thunk evaluation solution as for tracing GC.

We will build a cyclic graph, where all of the cycles pass through a
a root object, which is the recursion group dictionary. The root contains
one reference for each recursive definition in a mutual recursion group:
these are the 'trunks'. Each trunk may point directly at a recursive closure,
which contains a reference back to the root, or it may point at a tree structure
whose leaves include recursive closures (that point back to the root) as well
as nonrecursive values. The intermediate nodes of this tree are Lists, Records,
Piecewise_Functions, Composite_Functions, Closures.

At present, Curv is limited: every root must be a recursive closure.
We are looking for a more general solution.

After the root object is constructed, but before the trunk values have been
copied to Frame slots (for a 'let') or Module slots (for a module), all of
the reference counts in the graph are in their 'ground state'. The refcounts
are all > 0, but nothing external to the graph points to any of the nodes.
In the future, when the graph returns to its ground state after all external
references are dropped, the graph has become garbage and we want to collect it.

We built this graph using the evaluator. We don't know its structure ahead of
time using compile time analysis. Except that, we do have a distinguished
object, the root, through which all the cycles flow, and whose structure is
known at compile time.

Is there some way to hack this object to make it collectible via reference
counting? The obvious problem right now is that the condition we want to check
for is not local to a single object (the refcount is zero) but global to the
graph (all the refcounts that are part of a cycle are in the ground state).

 0. Brute force.
     * Starting at the root, we traverse the entire graph. If we reach the
       root again, then we got there via a cycle. So then we back up, and
       mark every node in the cycle. Now every node that was part of a cycle
       is marked. The 'mark' consists of: the reference count ground state,
       and a pointer to the root.
     * When we decrement an object's reference count, we check if it is marked.
       If it isn't marked, we free the object on count zero.
       If it is marked, we go to the root then traverse the entire graph,
       checking each refcount to test if each node's refcount is in the ground
       state. If all refcounts are in ground state, then we free the graph.
 
 1. Optimized(1) brute force.
    Instead of checking that each node's refcount is ground state, we instead
    store the sum of all the ground state refcounts in the root, and do one
    comparison.
     * The root contains the sum of all cyclic node ref counts when they are
       in ground state.
     * It also contains the sum of all cyclic node ref counts in current state.
     * When incrementing the refcount of a cyclic node, we also increment
       the sumcount in the root.
     * When decrementing the refcount of a cyclic node, we also decrement
       the sumcount in the root. When the sumcount == the ground sum count,
       then we free the graph.

 2. Optimized(2) brute force.
    Instead of containing a refcount, an object contains a Liveness value,
    which is a discriminated union of two cases: a refcount, and a pointer
    to a root. There are two operations on Liveness: claim and release.
     * init: For a non-cyclic object, initialize the Liveness to a refcount
       with count 0. For a cyclic object, initialize the Liveness to a root
       pointer. The root has a graph_refcount which is initialized to 0.
     * claim: If it's a refcount, increment the refcount.
       If it's a root pointer, increment the graph_refcount of the root object.
     * release: If it's a refcount, decrement the refcount. Free the object
       on count zero. If it's a root pointer, decrement the graph_refcount
       of the root. Free the graph on count zero.
    A Liveness value is a pointer-sized value (32 or 64 bits), with the low
    order bit used to distinguish the two cases: 0->root pointer, 1->refcount.
    The refcount is incremented/decremented by adding/subtracting 2, and we
    free the object when the refcount reaches 1.
    The root object is (obviously) not an independently refcounted object.

Idea (2) is the one I'm going forward with.

Update: I finally found prior art for my "cyclic reference counting" idea.
J.P.H.Aerts, 1981, "Implementing SASL without garbage collection"
<https://pure.tue.nl/ws/files/4260710/252975.pdf>

"Weak references" are a technique for breaking cycles so that a cyclic object
can be reclaimed by conventional refcounting. In this proposal, a recursive
closure has an uncounted reference to its recursive binding dictionary
(aka the root object of this proposal), and the root contains uncounted
references to the trunk objects. This reminds us of weak references, which are
also uncounted references. If there was only a single externally referenceable
object in the entire cyclic structure (ie, a single closure object), then we
could dispense with indirect reference counting, and rely on a weak reference
from the root to the closure to make conventional reference counting work.
Perhaps this alternate representation could be used as an optimization.
However, once there are multiple externally referenceable objects in the same
cyclic graph, they need a shared reference count, because the entire graph must
continue to exist as long as any one of the nodes is externally referenced.

What if: I don't enforce the restriction that recursive references must be
inside lambdas? Since the trunk expressions are eagerly evaluated, the only
other places recursive references will work are in unevaluated branches of
conditional expressions. This means that some trunk values may not be cyclic
values: after trunk evaluation, such values will have immediate refcounts,
instead of indirect refcounts. (Or a trunk value could even be a cyclic
value from a different cyclic object!) Nothing will break. The only issue is
that holding such values in the root may increase memory pressure, because
the values may not be freed as early as possible.

What if: Closures don't have two separate dictionaries (recursive and
non-recursive)? The issue is increased memory pressure, as mentioned above.

What if: The root is an externally referenced object? Eg, maybe it is a module,
and module values serve double-duty as the root for any recursive definitions
they contain. Then the root's refcount is the sum of the cyclic values in its
cycle, plus the # of external references. No problem (other than the issue of
memory pressure): The module value continues to exist, even after there are no
more external references to it, if it is referenced by cyclic objects. And
those cyclic objects may not depend on all the fields in the module.
The problem is addressed by segregating the recursive values in a separate
root object that is referenced by the main module object.

These memory pressure issues also exist in the garbage collection world.
There are imprecise collectors, such as the Boehm collector, which sometimes
misclassify dead objects as live. Even with a precise collector, you can have
storage leaks, because an object can become "algorithmically dead": the
algorithm has reached a state beyond which it will never access the object
again, even though there is still a live reference to it in memory.

What if: I don't evaluate all of the thunks immediately? What if I want lazy
data structures? Well, in this design, a thunk can only be evaluated in the
context of a specific root object. After evaluating a thunk, we traverse the
resulting value tree, and if any of the values are closures that reference
the root, then those closures are given indirect refcounts pointing to the root,
and likewise for any values pointing directly or indirectly to those closures.
The thunks can only reside in a root object. If we have module values that are
also roots, then we could lazily evaluate module fields.

How do lazy data structures interact with COW?
 * A CRThunk (Cyclic value Reference Thunk) contains two fields: a counted
   reference to a root object, and a trunk index. To evaluate the thunk,
   we force the specified trunk value to be evaluated, then we replace the
   thunk with the trunk value.
 * COW data structures use CRThunks to represent unevaluated cyclic values.
   CRThunks can be copied without any adverse consequence. When any copy of
   a CRThunk is forced, it is replaced by a reference to the same unique
   cyclic object as all of its clones.
 * CRThunks are needed if the trunk values in a root are themselves lazy.

We support:
 * Lisp-style cyclic data structures,
 * Haskell-style lazy infinite data structures,
 * Curv's prohibition of cyclic/infinite data structures,
 * or a hybrid, as determined by the data structure constructors.
We also support efficient incremental update of immutable data structures
using copy-on-write (COW).

Do nested recursive scopes complicate the implementation?

The details are in the initial construction of a cyclic value.
 * During analysis, we recognize definitions and groups of definitions that
   are recursive and mutually recursive. We group such definitions into
   "recursion groups", which eventually give rise to cyclic structures at run
   time. While recursive definitions are being analysed, each recursive
   reference is initially compiled to a Symbolic_Ref (we initially don't know
   the recursion group/cycle id or the index into the root object).

   Each recursion group is assigned a slot in the stack frame (which
   contains a pointer to the Cyc_Root object. Each recursive reference is
   compiled to a Recursive_Ref, which contains group id/root id (mapping to a
   slot id), plus an index into the group.

   which identifiers are recursive references,
   an definitions are
 * To construct a cyclic value:
    * The root (Cyc_Root) is initialized with an array of thunks
      (Open_Thunk wrapped in a Value).
    * Then we force the thunk in each trunk. To force a single trunk, use:
         thunk = trunks[i];
         trunks[i] = Value{}; // missing Value
         trunks[i] = thunk->eval(frame, root);
      The reason for storing a missing value in the trunk before evaluating it
      is that if we try to recursively evaluate the same trunk a second time
      during thunk->eval(), then we can check for the missing value and take
      special action.
    * To evaluate the thunk, we do this:
         Open_Thunk::eval(Frame& fr, Cyc_Root* root)
            auto old_root = fr.cyc_root_;
            fr.cyc_root_ = root;
            auto result = this->expr_->eval(fr);
            fr.cyc_root_ = old_root;
            return result;

Can lazy data structures be infinite? (1) Can this scheme support infinite data
structures? (2) Can this scheme support lazy data structures but prohibit
infinite ones? What about this: `a = [1, ...a]`?
 1. We can prohibit infinite data structures. Curv will work this way.
    Even if lists are lazy, when the thunk for `...a` is forced, we will report
    an error "Illegal recursive reference" for the subexpression 'a'.
 2. We can support infinite data structures.
    * At compile time, we notice that `...a` contains a recursive reference.
      A list constructor may contain only one such element, it must be the final
      element. A special representation is used for lazy tailed lists (LTLs).
    * An LTL is a cyclic object. The root contains one trunk, which is a
      reference to the LTL object. The LTL itself has an indirect reference
      count pointing at the root, it has slots for the head elements of
      the list, and it has a final slot for the tail element. The tail is
      initially a CThunk containing the tail expression (in this case, 'a').
    * The structure is '[1, ...a]' where 'a' is a CThunk. Previously, CThunks
      only existed in the root object. I am not sure about this.
    * When the tail thunk is forced, we first evaluate the tail expression,
      and we get the LTL value. Next, we update the LTL object to contain the
      thunk evaluation result, using COW, and the result has this structure:
          [1, ...[1, a]]
      The inner LTL has the original thunk for 'a'. If we force that thunk,
      we get
          [1, ...[1, ...[1, ...a]]]
      And so on.

Data Types:
  Cyc_Root : Shared_Base -- array of Values (initially thunks)
    refcount is # of external references to objects in the cycle
  Open_Thunk : Ref_Value -- an internal/open thunk: Shared<Operation>
    Only appears in the trunk array in Cyc_Root, for non-lazy trunk values.
    Much cheaper than a Closed_Thunk.
  Closed_Thunk : Ref_Value -- a closure, takes Cyc_Root as argument.
    (The Cyc_Root argument is passed in the cyc_root VM register.)
    Only appears in the trunk array in Cyc_Root, for lazy trunk values.
  Cyc_Ref : Ref_Value -- { Shared<Cyc_Root> root, int trunk_id }
    A reference to a lazy trunk value in a cyclic structure.
    The trunk value must be a Closed_Thunk or a proper value.
    A copyable lazy evaluation thunk, used in lazy data structures.
    A Cyc_Ref is an improper value, replaced by a proper value on first
    reference, evaluating the corresponding Closed_Thunk if necessary.

Implementation: Thunks
======================
The basic intuition, as I recall, is that recursive definitions are
represented by the same thunks we create for the Tracing Garbage Collector
implementation. In that implementation, we evaluate the thunk on first reference
and replace it by the result value, which creates a cycle. In this
implementation, we keep evaluating the thunk each time we need the value,
so that we don't create a cyclic graph.

The remainder of this paper are the notes I wrote while developing the idea.
The notes are somewhat disorganized.

--------------------------------------------------------------------------
Every definition 'x = expr' that contains lambdas containing recursive
references has an associated thunk.

TODO
----
* Every data definition has a thunk. Nonlocal refs in the definiens
  compile into nonlocal refs to the thunk nonlocals dict. (No semantic change)
  * Definiens_Scope builds the nonlocals dictionary.
  * Data_Definition::make_setter now sets up for thunk evaluation.

Theory
------
A recursive data definition (`f = expr` where expr is not a lambda)
defines a recursive function 'f', or a non-recursive data structure containing
recursive functions (eg, a callable record).

Recursive references must be contained within lambda expressions,
or an error is reported, so that we can report an error on `x = x + 1`.

Recursive references are not supported in definitions like `pat = expr`
where `pat` is not an identifier.

When we compile the `expr` in `f = expr`,
 0. If the nub of `expr` contains no lambda expressions, it is a "data
    definition", otherwise it is a "function definition". We need to build
    a nonlocals dictionary for the latter. All of the nonlocal references in
    `expr` are placed in this nonlocals dictionary. All top level lambdas in
    the nub of a "function definition" share the same nonlocals dictionary,
    which is also used by a thunk that we may need to build for `expr`.
 1. Any recursive reference (eg, to `f`) outside of a lambda is an error:
    "illegal recursive reference".
 2. Recursive references are permitted inside lambda expressions.
    Each top-level lambda within `expr` is marked as having shared-nonlocals.
    Initially, each definition belongs to its own recursion group.
    Tarjan's SCC algorithm unifies mutually recursive groups.
    After unification, each recursion group has a nonlocals dictionary that
    contains the union of the nonlocal references of each definition
    in the group.

Requires changes to Recursive_Scope::analyse_unit(unit, id).

If a data definition definiens contains no lambda expressions, it is
compiled normally. If it contains lambdas, then all nonlocal references,
inside and outside of lambdas, are collected in a single nonlocals dictionary
that is shared with all members of the recursion group.

How are shared nonlocals dictionaries created now?
* every Unit has `Symbol_Map<Shared<Operation>> nonlocals_`
* make_function_setter() combines the nonlocals_ of a set of Units into the
  shared dict for the recursion group.

New design. Create a nonlocals dictionary for every data definition.
 1. One pass. Every data definition has a thunk. Nonlocal refs in the definiens
    compile into nonlocal refs to the thunk nonlocals dict.
 2. Two pass. Optimize the output of the first pass for more efficient nonlocal
    references.

How do we mark a lambda as using a shared nonlocals dictionary?
 * Perhaps Lambda_Phrase::analyse(env) queries the environment to see if it
   is embedded in the definiens of a simple data definition (simple means
   the pattern is an identifier).
 * The flag is called `bool Environ::lambda_inherits_shared_nonlocals_`.
 * By default, it is false for a root environment, or is inherited from the
   parent environment.
 * Definiens_Scope sets it to true.
 * Lambda_Scope sets it to false.

How does Recursive_Scope::analyse_unit know if an identifier is an illegal
recursive reference (is this inside or outside a lambda)?
 * Perhaps a bool argument passed to analyse_unit makes this distinction.
 * How is the `recursion_ok` argument value computed?
   unit is function definition
   || (unit is simple data def && reference is inside lambda)
 * How do we know the reference is inside a lambda?
   * Env::lookup is passed a bool argument `is_nonlocal`.

------------------------------------------------------------------------------
Run time representation of a set of recursive definitions.
 * There is a set of binding slots, one for each variable.
   These are initialized one recursion group at a time, in dependency order.
 * Within a recursive nonlocals dictionary, a recursive reference to a binding B
   within the same definition set has a special representation.
    * The general representation is a Thunk_Lambda. The definiens for B is
      compiled into a thunk. A Thunk_Lambda is a thunk without nonlocals.
      Note, the thunk uses the closure's nonlocals object for its nonlocals.
    * As an optimization, in the case where the definiens for B is a lambda,
      we store a Lambda object (a closure without the nonlocals).

During the evaluation of 'expr', the function 'f' must not be called.
 * We guarantee there will be no attempt to fetch the value of frame slot 'f'
   because references outside of lambdas have already generated compile errors.
 * Within a lambda, a reference to 'f' is actually a reference to the closure's
   nonlocals object at f. This is a ThunkLambda. This is converted to a value
   by evaluating the thunk. But when evaluating the definiens, we expect to
   construct the closure (that references f) but we don't want to call the
   resulting closure.
This is only enforced during the first evaluation of 'expr', when we obtain
the initial value for the frame slot 'f'.
 * There is a single ThunkLambda object shared by all closures that have
   captured a nonlocal reference to 'f'.
 * Prior to the first evaluation of 'expr', we 'poison' the ThunkLambdas for
   all of the bindings in the recursion group. The ThunkLambdas can be captured
   by closures but an error is reported if they are evaluated.
 * After 'expr' is evaluated, we unpoison the ThunkLambdas.

With this scheme, in `pat = expr`, `pat` can be 'identifier'
or 'identifier :: predicate'. A further generalization to support arbitrary
patterns could work by prefixing 'let pat = expr in' to each closure body
that references any of those variables, then optimizing from there.

Optimization:
 * Instead of storing ThunkLambda and Lambda in the nonlocals dictionary
   and referencing them using Symbol_Ref (these are compile time constants),
   use special opcodes Nonlocal_Thunk and Nonlocal_Lambda, which contain the
   ThunkLambda or the Lambda. Then perform optimizations over these opcodes.

### Alternative A0
When we compile the `expr` in `f = expr`,
 1. Any reference to `f` outside of a lambda is an error:
    "illegal recursive reference".
 2. Any reference to `f` inside a lambda causes that lambda to use the shared
    nonlocals object NL that belongs to f's recursion group. Such a lambda is
    called a 'recursive lambda', and is marked as such.

If `expr` contains recursive lambdas, then we compile `expr` into a thunk.
All of the nonlocals in `expr` are added to NL.
During thunk evaluation, the thunk frame's nonlocals_ is set to NL.
When a recursive lambda is evaluated into a closure, it uses this NL as the
nonlocals_ field of the closure.

### Alternative T
A function closure (value) contains a 'nonlocals' data structure, which contains
the values of all non-local bindings captured by the closure. In the case of
a recursive function 'f', the nonlocals structure should logically contain the
value of 'f'. However, that creates a cyclic data structure, which breaks
reference counting (it causes a storage leak).

To break the cycle, we use a special representation for recursive nonlocal
bindings. Instead of storing the full closure value for 'f' within its own
nonlocals structure, we just store a Lambda object, which consists of everything
that a closure has, minus the nonlocals. Then we combine the Lambda with f's
nonlocals structure (which is already in hand) when we need to reconstruct f's
value from its nonlocals entry.

In the case of a general recursive function definition ('f = expr' where 'expr'
is not recognized as a special case (ie, as a lambda expression), then 'expr'
can potentially evaluate to any kind of function value, not just a closure.
It could also evaluate to a Piecewise_Function, or a module with a 'call' field.
So we need a more general representation for recursive value references
within the nonlocals structure.

The following solution using thunks is quite general. `f` can be a function,
or a callable record, or a more general data structure containing functions.

Recursive references must be contained within lambda expressions, or an
error is reported, so that we can report an error on `x = x + 1`.

Ensuring that recursive references are wrapped in lambda expressions is not
enough to be able to report errors on all illegal recursive forms.
Here's an infinite loop:
    f = (()->f)();
Here's a loop that will exhaust memory building an infinite data structure:
    f = [(()->f)()];
(NB: Lazy infinite data structures are out of scope for this investigation.)
A requirement I wrote above:
 * During the evaluation of 'expr', the function 'f' must not be called.
   If it is called, then an error is reported at the site where 'f' is called
   (illegal recursive reference to 'f').
It's simple. `f = expr` is implemented by converting `expr` to a thunk.
Normally we expect to evaluate the thunk and get back a function, or callable
record. Or a more general data structure containing functions.
If the thunk invokes itself recursively at runtime, we report an error.

Here's an earlier description of this approach:
  If a recursive definiens isn't a lambda expression, then it is made into 
  a call-by-name thunk that is evaluated on every reference from inside the 
  recursion group. From outside the group, it's a proper value in a slot. 

A Thunk is a kind of parameterless function. A Thunk object has:
    Shared<const Operation> body_;
    Shared<const Module> nonlocals_;
    unsigned nslots_;
    bool evaluating_ = false;
A Thunk_Lambda is missing the nonlocals:
    Shared<const Operation> body_;
    unsigned nslots_;

Implementation of 'f = expr':

  When we compile recursive data definition 'f = expr', we compile 'expr' as a
  ThunkLambda TL. All of the nonlocal references within 'expr', including 'f'
  itself, will be included in NL, the nonlocals object for f's recursion group.

  At runtime, when we initialize the bindings in f's recursion group:
   * We set NL.f to the ThunkLambda TL. Can't store a Thunk because that's
     a reference cycle through NL.
   * We set f's frame slot to the result F of evaluating the thunk.
     The thunk is evaluated by creating a thunk_frame whose nonlocals is NL,
     and calling thunk.body->eval(thunk_frame) yielding F.
     No cycle: F will reference NL, but NL won't reference F.

  During that initial thunk evaluation,
   * If we reference a nonlocal containing a ThunkLambda, outside the context
     of capturing a nonlocal while building a closure (see below), then that
     is an error: "illegal recursive reference". This handles the case of
     a recursive reference to 'f' within 'expr' that is not wrapped in a lambda.
   * While constructing a closure, if we capture a non-local variable reference
     that contains a ThunkLambda, then we construct a Thunk from the ThunkLambda
     and the Frame::nonlocals. We store that Thunk in the closure's nonlocals.
     This handles the case of a recursive reference to 'f' within 'expr' that
     is wrapped in a lambda.
   * While evaluating a closure call, if the closure body fetches a nonlocal X
     that contains a Thunk T, then we evaluate the Thunk as follows:
      * If T.evaluating is true, then throw an error:
        "illegal recursive reference".
      * Otherwise, set T.evaluating = true;
      * Construct a thunk_frame for evaluating the Thunk T, whose size
        is T.nslots and whose nonlocals is T.nonlocals.
      * Evaluate the thunk's body in thunk_frame and get the resulting value:
        T.body.eval(thunk_frame)
      * Reset T.evaluating_ back to false.

This implementation could be optimized, but it's a nontrivial subject.
  * As a performance optimization, should we store the thunk result back in
    the closure's nonlocals? I don't think this causes a reference loop.
    I think it causes memory bloat.

---
   * When we capture a non-local variable reference to f (when constructing a
     closure), we construct a thunk from the thunklambda, and store the thunk.
     * The thunk will additionally contain a reference to NL, but that doesn't
       introduce a cycle, because NL will not refer to the closure.
     * Suppose that, instead of storing the thunk, we instead evaluated the
       thunk and directly stored the resulting value in the closure. That
       could create an infinite loop, building an infinite data structure.
           f=[(()->f)()];
     * Can we store the result of evaluating the thunk in the closure?
       Can it create a cycle? Can it create an infinite data structure?
     * Can we lazily replace the thunk with its value on first reference,
       or will that create a cycle?
   * While executing a thunk, when we reference a nonlocal that contains a
     ThunkLambda (which is different from capturing a nonlocal, see above),
     then we report an error: "illegal recursive reference".
   * When a nonlocal slot NL.s contains a Thunk, we convert it to a value:
     * We set NL.s.evaluating_ = true. If a Thunk is referenced when evaluating_
       == true, we throw an error: "illegal recursive reference".
     * We construct a frame for evaluating the Thunk T, whose size is T.nslots,
       and whose nonlocals is NL.
     * We evaluate the thunk's body in the frame and get the resulting value.
     * We reset NL.s.evaluating_ back to false.

Implementation of 'f = expr':
 * When we compile recursive data definition 'f = expr', we compile 'expr' as a
   ThunkLambda TL. Recursive references to 'f' are an error unless nested in a
   lambda expr. All of the nonlocal references within 'expr', including 'f'
   itself, will be included in NL, the nonlocals object for f's recursion group.
 * At runtime, when we initialize the bindings in f's recursion group:
   * We set NL.f to the ThunkLambda TL. Can't store a Thunk because that's
     a reference cycle through NL.
   * When we capture a non-local variable reference to f (when constructing a
     closure), we construct a thunk from the thunklambda, and store the thunk.
     * The thunk will additionally contain a reference to NL, but that doesn't
       introduce a cycle, because NL will not refer to the closure.
     * Suppose that, instead of storing the thunk, we instead evaluated the
       thunk and directly stored the resulting value in the closure. That
       could create an infinite loop, building an infinite data structure.
           f=[(()->f)()];
     * Can we store the result of evaluating the thunk in the closure?
       Can it create a cycle? Can it create an infinite data structure?
     * Can we lazily replace the thunk with its value on first reference,
       or will that create a cycle?
   * When a nonlocal slot NL.s contains a Thunk, we convert it to a value:
     * We set NL.s.evaluating_ = true. If a Thunk is referenced when evaluating_
       == true, we throw an error: "illegal recursive reference".
     * We construct a frame for evaluating the Thunk T, whose size is T.nslots,
       and whose nonlocals is NL.
     * We evaluate the thunk's body in the frame and get the resulting value.
     * We reset NL.s.evaluating_ back to false.
   * We set f's frame slot to the result R of evaluating the thunk T.

### Implementation of 'f = expr':
 * When we compile 'f = expr', we compile 'expr' as if it were the body
   of 'x -> expr x', yielding an operation tree E. This means that all nonlocal
   references within 'expr', including 'f' itself, will be included in NL,
   the nonlocals object for f's recursion group.
 * At runtime, when we initialize the bindings in f's recursion group:
   * Phase 1, initialize NL. We set NL.f to a magic value that throws an error
     on reference: "illegal recursive reference" at the reference to 'f'.
   * Phase 2, evaluate 'expr' using a Frame whose nonlocals object is NL.
     The result C must be a callable value, or we report an error.
     A definition like 'x = x' will report an error at this point.
     Without this evaluation step, 'x = x' would turn into an infinite loop.
     Store C in a temporary variable Ctemp.
   * Report an error if C is not a function. C cannot be a record with a
     `call` field, because phase 3 won't expose the extra record fields.
     * Okay, but what remedial action should the user take to fix the error?
       Suppose a library combinator starts returning a record callable,
       thereby breaking existing code?
   * Note that C cannot be stored in NL.f, because that will create a cyclic
     data graph, which breaks reference counting. Phase 3 fixes that.
   * Phase 3. Set f's frame slot to Ctemp. Set NL.f to a lambda object
     that contains the operation tree E and is equivalent to 'x -> expr x'.
     This means we re-evaluate expr on each recursive call to f, which is
     heavier than a recursive function in a garbage collected language.
     I don't see a way to use the value of C to initialize NL.f.




Implementation of 'f = expr':
 * Within the nonlocals object NL, the slot for 'f' is initialized to a thunk
   that reports an error if it is called.
 * 'expr' is evaluated. If the evaluation succeeds without an error,
   yielding a value C, then an error is reported if C is not a function.
   If C is a function, then we expect that the value of 'f' has been captured
   by one or more closures contained somewhere within C. However, all of
   those closures share the same nonlocals object NL, which we have at hand.
 * If `NL.f` is set to the value C, then we have a cyclic data graph,
   which breaks reference counting. So we have to break that cycle.
 * Let's require the value C to be a Closure. This closure consists of
   two parts: a Lambda plus a Nonlocals object (C.lambda and C.nonlocals).
   * We ignore the case where C is a general callable value, like a record
     with a 'call' member, or a non-closure function like a Piecewise_Function.
 * In the standard implementation of recursive functions, we store a Lambda
   in NL.f, and when 'f' is referenced, we reconstruct the closure by
   combining the lambda NL.f with the nonlocals NL. That won't work here,
   since we normally expect C.nonlocals != NL.
 * What does work is the standard workaround for this design flaw.
   Instead of writing `f = expr`, write `f = x -> expr x`.
   So let's duplicate that logic.
 * It is not good enough to simply rewrite a recursive data definition
   'f = expr` to `f = x -> expr x` because it fails to do the error checking
   done by the first few steps. Eg, `x = x` would be equivalent to `x a = x a`
   and would be an infinite loop rather than an error.
 * When we compile 'f = expr', let's compile 'expr' as if it were the body
   of 'x -> expr x'. This means that all nonlocal references within 'expr'
   will be included in NL (including 'f' itself).
 * Then, we evaluate 'expr' using a special Frame whose nonlocals object
   is NL. Before evaluation, we set NL.f to a magic value that fails on
   reference. After evaluation, we check the result C is a function.
 * Then we set NL.f to the Lambda of 'x -> expr x', substituting in the
   Operation tree for expr.

------
This is a generalization of special case handling for recursive 'match'
definitions. If we build the necessary machinery, we don't need to put a
lot of special case code into the compilation of 'match' calls.

is compiled into `f x = x >> expr`.
Note this aborts at runtime if expr does not return a function.

But this means
    x = x
compiles to
    x a = x a
which is wrong. Either the definition is a compile time error, or 'x'
is a thunk that runs in an infinite loop.

Maybe there is a restricted subset of definitions for which that design
will work.

Thunkification
--------------
Recursive data definitions should be compiled into thunks.
All the definitions in a mutual recursion group compile into
* a slot containing a shared nonlocals module
* 
