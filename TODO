Throw runtime exceptions for domain errors, instead of returning null.
* throw Runtime_Error(Syntax&, "domain error")
A Syntax object contains a source location (points to the span of characters
in a particular script from the first to the last token, plus the script).
Can print filename/lineno, or text editor can highlight the bad expression.
* Syntax::Syntax(Script&)
* Script& Syntax::source_file()
* Token Syntax::first_token()
* Token Syntax::last_token()
* int Syntax::lineno()
A Token does not contain a Script. That's in the Scanner, and in the Syntax.
New design forces parser to ensure that every Syntax begins and ends in the
same source file.
* throw Syntax_Error(script, token, message)
Better exception names?
* Error_At_Token(script, tok, msg), Error_At_Syntax(syntax, msg)
  Both have the same interface for getting filename, lineno, etc.
  Common subclass curv::Error.

How does this exception work when using LLVM? Can I embed object pointers
in an LLVM generated executable? They have to survive passing through IR.
I can embed them as uint64_t.

Introduce a semantic analyzer that converts a syntax tree to a meaning tree.
Evaluate the meaning tree (not the syntax tree).

Add builtin functions like sin(x).

Print floating point numbers accurately.

build system?
* Fast. Correct: auto track dependencies, rebuild on recipe change,
  delete stale objects. High level: standard abstractions that are portable
  across linux/osX/win. Cross project dependency discovery and configuration
  (see pkg-config). Packageable: libcurv can be packaged for Ubuntu; build tools
  are already in ubuntu repo.
* Should I use pkg-config for build-time dependency discovery and configuration?
  Do I install a *.pc file that records compiler and linker flags required to
  use the curv library? Can I build an Ubuntu package for libcurv?
* Google Bazel is fast, correct and high level. Still in beta. Missing some
  platform support, cross project dependencies. Wait for 1.0 in 2017.
* cmake is popular and well supported on multiple platforms.
  It has comprehensive portability abstractions.
  It is more correct than expected, given that it generates makefiles.
  Rebuilds on recipe change, tracks header dependencies. Doesn't delete stale
  products. (Has an experimental option to generate ninja files.)
* ninja is fast. It rebuilds if recipe changes. Header dependencies depend
  on the gcc feature to output dependencies (suboptimal, I'd rather it monitor
  which files are opened by build tools).
  Need a generator: ninja+cmake, ninja+gen, ninja+bash, ...
* tup is fast and correct. Tup determines hdr file dependencies automagically.
  Tup rebuilds if recipe has changed. Tup deletes build products that can
  no longer be generated. Tup has a high level command language (Lua).
  * Tup is not in the Ubuntu package universe. There are PPAs...
    Building from source isn't working...
  * Tup is deeply magical and edgy. It uses FUSE, performs kernel magic to
    overlay source and object directories, and makes tools confused
    about what their current directory actually is, causing some things to
    break. This can be overcome using the ^c chroot flag, which requires
    setuid root. FUSE probably no longer works in MacOS ElCapitan due to SIP.
  * So edgy it might discourage contributors. The automagic dependency tracking
    requires deep magic that is also flaky: fuse, chroot, dynamic lib injection.
    Eg, the ConEmu terminal emulator breaks DLL injection on Windows.
    Tup is reported to not work on FreeBSD (fuse works differently).
* redo. Simple, powerful, elegant. Also slow (as fast or slower than make).
* So, probably cmake+ninja.

unit tests
language reference manual

Later:
* Digit separator ' in numerals (like C++14).
* Support ' in identifiers (like Haskell).
* Support `foo` quoted identifiers.
  Compatibility with OpenSCAD identifiers, GUI interfaces that display
  parameter names as GUI labels, JSON object keys.
* UTF-8 support. Rewrite scanner in re2c.
* Parser: consider Boost::Spirit (recursive descent) or Lemon (similar to
  Bison, thread safe, LALR(1)), or Bison with %pure-parser (thread safe).
  Is Lemon better than Bison? Lemon:
  * the tokenizer calls the parser (instead of vice versa)
  * terminals/non-terminals don't need to be declared. Terminal name has
    initial uppercase letter.
  * productions are less error prone. Instead of $1, $2 (requires counting),
    expr(A) ::= expr(B) PLUS expr(C). { A = B + C; }
  * no mid-actions, one action per rule.
  * no repetitions and optionals.
  * small footprint: small code with no dependencies
* localization
