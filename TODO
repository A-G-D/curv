# TCAD0 (Calculator):
* builtin functions:
  * error reporting for bad arguments:
    * report location of bad argument. (What if two args conflict, like 0/0?)
    * OR: throw aux::Exception(to_string(x,"/",y,": domain error"))
  * printing a builtin function? currently, <function>
* compile parse tree into Meaning, then Meaning::eval()
* string literals, [a,b,c] list literals, no list comprehensions
* seq@i, len(seq), concat[s1,s2,s3]
* && || !, if-else, relational ops
* more math functions
* Print floating point numbers accurately.
* broader unit testing

Introduce a semantic analyzer that converts a syntax tree to a Meaning tree.
Evaluate the meaning tree (not the syntax tree).
* look up identifiers
* type inference
* etc.

refactor: reimplement scanner using re2c. (Later add utf8 support.)

Add builtin functions like sin(x).

Print floating point numbers accurately.

Full set of operators.

String and list values.

# TCAD1 (basic scripting, LLVM)
* named functions (top level only for now).
* LLVM based evaluator. Compile Meaning to LLVM IR.
  Embed raw function pointers and Values in IR as bit patterns.

# TCAD2 (nested scopes)
* nested functions, function literals, let() expressions.
* script literals
* exceptions with precise location reporting

more unit tests
language reference manual

---------------------------------------------------------------------------
Later:
better error messages, print line with caret:
  ERROR: the 'what()' error message
  file foo.scad, line 1[10-15], token foobar
    x = foobar();
        ^-----

* Digit separator ' in numerals (like C++14).
* Support ' in identifiers (like Haskell).
* Support `foo` quoted identifiers.
  Compatibility with OpenSCAD identifiers, GUI interfaces that display
  parameter names as GUI labels, JSON object keys.
* UTF-8 support. Rewrite scanner in re2c.
* Parser: consider Boost::Spirit (recursive descent) or Lemon (similar to
  Bison, thread safe, LALR(1)), or Bison with %pure-parser (thread safe).
  Is Lemon better than Bison? Lemon:
  * the tokenizer calls the parser (instead of vice versa)
  * terminals/non-terminals don't need to be declared. Terminal name has
    initial uppercase letter.
  * productions are less error prone. Instead of $1, $2 (requires counting),
    expr(A) ::= expr(B) PLUS expr(C). { A = B + C; }
  * no mid-actions, one action per rule.
  * no repetitions and optionals.
  * small footprint: small code with no dependencies
* localization

build system?
* Fast. Correct: auto track dependencies, rebuild on recipe change,
  delete stale objects. High level: standard abstractions that are portable
  across linux/osX/win. Cross project dependency discovery and configuration
  (see pkg-config). Packageable: libcurv can be packaged for Ubuntu; build tools
  are already in ubuntu repo.
* Should I use pkg-config for build-time dependency discovery and configuration?
  Do I install a *.pc file that records compiler and linker flags required to
  use the curv library? Can I build an Ubuntu package for libcurv?
* Google Bazel is fast, correct and high level. Still in beta. Missing some
  platform support, cross project dependencies. Wait for 1.0 in 2017.
* cmake is popular and well supported on multiple platforms.
  It has comprehensive portability abstractions.
  It is more correct than expected, given that it generates makefiles.
  Rebuilds on recipe change, tracks header dependencies. Doesn't delete stale
  products. (Has an experimental option to generate ninja files.)
* ninja is fast. It rebuilds if recipe changes. Header dependencies depend
  on the gcc feature to output dependencies (suboptimal, I'd rather it monitor
  which files are opened by build tools).
  Need a generator: ninja+cmake, ninja+gen, ninja+bash, ...
* tup is fast and correct. Tup determines hdr file dependencies automagically.
  Tup rebuilds if recipe has changed. Tup deletes build products that can
  no longer be generated. Tup has a high level command language (Lua).
  * Tup is not in the Ubuntu package universe. There are PPAs...
    Building from source isn't working...
  * Tup is deeply magical and edgy. It uses FUSE, performs kernel magic to
    overlay source and object directories, and makes tools confused
    about what their current directory actually is, causing some things to
    break. This can be overcome using the ^c chroot flag, which requires
    setuid root. FUSE probably no longer works in MacOS ElCapitan due to SIP.
  * So edgy it might discourage contributors. The automagic dependency tracking
    requires deep magic that is also flaky: fuse, chroot, dynamic lib injection.
    Eg, the ConEmu terminal emulator breaks DLL injection on Windows.
    Tup is reported to not work on FreeBSD (fuse works differently).
* redo. Simple, powerful, elegant. Also slow (as fast or slower than make).
* So, probably cmake+ninja.
