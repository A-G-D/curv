http://taichi.graphics/wp-content/uploads/2019/09/taichi_lang.pdf
https://github.com/yuanming-hu/taichi

Taichi: A Language for High-Performance Computation on Spatially Sparse Data Structures

3D visual computing data are often spatially sparse. To exploit such sparsity,
people have developed hierarchical sparse data structures, such as multi-level
sparse voxel grids, particles, and 3D hash tables. However, developing and
using these high-performance sparse data structures is challenging, due to
their intrinsic complexity and overhead. We propose Taichi, a new data-oriented
programming language for efficiently authoring, accessing,and maintaining such
data structures. The language offers a high-level, data structure-agnostic
interface for writing computation code. The user independently specifies
the data structure. We provide several elementary components with different
sparsity properties that can be arbitrarily composed to create a wide range
of multi-level sparse data structures. This decoupling of data structures from
computation makes it easy to experiment with different data structures without
changing computation code, and allows users to write computation as if they
are working with a dense array. Our compiler then uses the semantics of the
data structure and index analysis to automatically optimize for locality,
remove redundant operations for coherent accesses, maintain sparsity and
memory allocations, and generate efficient parallel and vectorized instructions
for CPUs and GPUs.

Our approach yields competitive performance on common computational kernels
such as stencil applications, neighbor lookups, and particle scattering. We
demonstrate our language by implementing simulation, rendering, and vision
tasks including a material point method simulation, finite element analysis,
a multigrid Poisson solver for pressure projection, volumetric path tracing,
and 3D convolution on sparse grids. Our computation-datastructure decoupling
allows us to quickly experiment with different data arrangements, and to
develop high-performance data structures tailored for specific computational
tasks. With 1/10th as many lines of code, we achieve 4.55Ã— higher performance
on average, compared to hand-optimized reference implementations.
