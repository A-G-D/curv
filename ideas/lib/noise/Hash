rand(seed): The API
===================
This is an okay API to start with.
These functions take an argument (num, vec2, vec3 or vec4)
and hash them into floating point numbers that are uniformly distributed
in the range >=0 and <1.
    rand(seed)  // result is num
    rand2(seed) // result is vec2
    rand3(seed) // result is vec3
    rand4(seed) // result is vec4

Problem: piecewise functions not supported by Shape Compiler.
What happens: "this function is not supported" error for a piecewise function
value returned by `match`.

Solutions:
* Piecewise_Function::sc_call_expr() is defined to do something reasonable.
  Compile argument, get its sc_type, search component functions for one whose
  pattern matches the sc_type.

A good white-noise hash function for the GPU
--------------------------------------------
To hash a 32 bit float to a uniformly distributed random number in [0..1).

We might provide multiple hashers with different tradeoffs (eg, speed vs
quality). Noise functions are parameterized by a hasher. Even if we do, the
default hasher should work well in any context. It should be:
* Fast
* Portable (same results on CPU and across GPU models)
* High quality (no visual artifacts)
* Scale independent (no visual artifacts when the scale changes due to
  zooming in and out).

Old code uses trig and exponential operations for hashing, because bitwise
operations aren't available in OpenGL 2.1 or WebGL 1. There are two problems:
* The hashes are scale dependent. They only produce good results in a
  restricted range. You need different magic numbers for different ranges.
* The hashes are not portable across GPUs, due to varying implementations
  of the trig and exponential functions.

You can make portable hashes using float addition and multiplication.
But the results are still scale dependent.

For high quality, scale independent hashing, you need to convert the float
to a bit array (floatBitsToUint), and use bitwise operators. This requires
OpenGL 3.3, OpenGL ES 3.0 or WebGL 2. That's how the default hasher works.

This approach may not be the fastest:
* Brian Sharpe says "Modern cards can also perform integer hashing which
  in some cases produce superior results but will often still run slower than
  floating point operations."
  * int multiply is often slower than float multiply.
  * otherwise, int ops are generally the same speed as float ops.
  * but there may be more float arithmetic units than int arith units.
* "on Nvidia hardware, there can only be 32 shifts executing at once,
  where there can be 128 other bitwise operations." -- the internet

Marc Olano, TEA2 hashing
------------------------
Olano, 2005, https://www.csee.umbc.edu/~olano/papers/mNoise.pdf
    Improvements to Perlin noise on the GPU.
    Discusses the BBS or blumblumshub hash. -- now obsolete
    Note, Olano *invented the shader*.

S Tzeng, 2008, Parallel White Noise Generation on a GPU via Cryptographic Hash
http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.650.2121&rep=rep1&type=pdf
    They use MD5 with 64 rounds (!), and demonstrate that the output has
    excellent statistical properties. The output gets worse if you reduce
    to 32 or 16 rounds. This is very slow. Do not use.

Olano, 2010, GPU Random Numbers via the Tiny Encryption Algorithm
https://www.csee.umbc.edu/~olano/papers/GPUTEA.pdf
    TEA, the Tiny Encryption Algorithm
    Faster than MD5, and "good enough" to avoid visual artifacts.
    Better than BBS.
    Tuneable for speed/quality tradeoff.

Plus the blog post:
https://umbcgaim.wordpress.com/2010/07/01/gpu-random-numbers/
"Lots of graphic tasks work well with just two rounds (of TEA)":
    uvec2 v = <input>;
    v.x += ((v.y<<4u)+0xA341316Cu)^(v.y+0x9E3779B9u)^((v.y>>5u)+0xC8013EA4u);
    v.y += ((v.x<<4u)+0xAD90777Du)^(v.x+0x9E3779B9u)^((v.x>>5u)+0x7E95761Eu);
    v.x += ((v.y<<4u)+0xA341316Cu)^(v.y+0x3C6EF372u)^((v.y>>5u)+0xC8013EA4u);
    v.y += ((v.x<<4u)+0xAD90777Du)^(v.x+0x3C6EF372u)^((v.x>>5u)+0x7E95761Eu);
Note: 2 32 bit inputs, 2 outputs, and 32 int operations.

Alexis Naveros hash functions
-----------------------------
http://amindforeverprogramming.blogspot.com/2013/07/random-floats-in-glsl-330.html

Lee C uses one round of Bob Jenkin's OAT hash. That has to be worse than
2 rounds of TEA. He doesn't properly test the output.

This hash is criticized on shadertoy: https://www.shadertoy.com/view/tstXWS
octaviogood says:
* Has the problem of being stuck at zero.
* It also has a few noticeable patterns when you look at the different bits.

In the comments of the blog post, Alexis Naveros complains about visual
artifacts, and provides a better set of hash functions:

    Note that the hash functions only need to care about the lowest 23 bits,
    with a focus on good avalanche behavior in the higher bits of that range.

    Here's what I use:

    uint hashInt1D( uint x )
    {
    x += x >> 11;
    x ^= x << 7;
    x += x >> 15;
    x ^= x << 5;
    x += x >> 12;
    x ^= x << 9;
    return x;
    }

    uint hashInt2D( uint x, uint y )
    {
    x += x >> 11;
    x ^= x << 7;
    x += y;
    x ^= x << 6;
    x += x >> 15;
    x ^= x << 5;
    x += x >> 12;
    x ^= x << 9;
    return x;
    }

    uint hashInt3D( uint x, uint y, uint z )
    {
    x += x >> 11;
    x ^= x << 7;
    x += y;
    x ^= x << 3;
    x += z ^ ( x >> 14 );
    x ^= x << 6;
    x += x >> 15;
    x ^= x << 5;
    x += x >> 12;
    x ^= x << 9;
    return x;
    }

Other Hashes
------------
"Quality hashes collection WebGL2" by nimitz 2018 (twitter: @stormoid)
12 hashes: 1-3D input x 1-4D output.
Based on testing and improvement of other people's hashes.
https://www.shadertoy.com/view/Xt3cDn
Poor code for uint->float conversion.
Output quality is criticized by antovsky, who responded with:
https://www.shadertoy.com/view/WsfXWX

https://github.com/BrianSharpe/GPU-Noise-Lib/blob/master/gpu_noise_lib.glsl
    Implements the FAST_32 hash.
    Also implements BBS (obsolete), and SGPP from Ashima.
    http://briansharpe.wordpress.com/2011/11/15/a-fast-and-simple-32bit-floating-point-hash-function/
    Looks good, esp. for generating lots of numbers in one call.
    Uses + - * / floor fract, so results should be portable across GPUs.
    It is scale sensitive.

http://github.com/ashima/webgl-noise
    Much referenced. Old-style scale-dependent hashing.

https://github.com/Auburns/FastNoiseSIMD
    SIMD C++ noise library.
    Interesting high level noise API.
    White noise is generated using integer multiply by primes:
    not ideal for GPU. In general, I expect the algorithms won't be optimal
    for GPUs.

GLM has noise functions.

Blender has a significant noise library implemented in GLSL, under an open
source licence. Blender uses OpenGL 3.3 (the same as Curv), and it uses a
hash function that performs bit manipulation on floating point representations.
So I should be able to use this code fairly directly.
  Note: It looks like this code is copied and pasted from just above everywhere.
  Many different functions for hashing floats onto pseudorandom numbers, and
  much of that code actually looks bad (roll your own bad code rather than use
  good code written by experts). Eg, dot+sin hash is low quality, Bob Jenkins
  hash is way too expensive on a GPU, and has needlessly high quality.

Converting a 32 Bit Hash to a Float in the range [0,1)
------------------------------------------------------
The correct code is given by A Mind Forever Programming:
    const uint mantissaMask = 0x007FFFFFu;
    const uint one          = 0x3F800000u;

    uint h = hash( floatBitsToUint( f ) );
    h &= mantissaMask;
    h |= one;

    float  r = uintBitsToFloat( h );
    return r - 1.0;
The conversion takes the low order 23 bits, discards the rest.
That's okay if the hash function output is designed to be used this way.
The final operation is r - 1. Let's run tests to show that 1 <= r < 2:
    0x3F800000 == 1.0
    0x3F800001 == 1.0000001192092896
    0x3F800000 | 0x007FFFFF == 1.9999998807907104

Nimitz uses poor techniques:
* from hash12: float(h)*(1.0/float(0xFFFFffffU))
* from hash22: float((h>>1) & 0x7fffFFFFu)/float(0x7fffFFFF)
  WTF? After h>>1, the high bit is 0, '& 0x7fffFFFFu' has no effect.
The results are biased (see Antovsky below), and it's expensive.
Maybe this poor code is a hangover from WebGL 1 which lacks uintBitsToFloat.

From comments in Nimitz:
* antovsky: when creating a float out of a uint, you're sometimes using
    *(1.0/float(0xffffffffU))
  and sometimes using
     & uvec4(0x7fffffffU))/float(0x7fffffff).
  Why the two different forms? Presumably you're masking off the sign bit for
  some reason in one place but not the other? Also is creating a float out of
  0xffffffff even valid? Isn't the max sane value for a 0.0 to 1.0 float 2^24
  since it only has 24 bits of significand?
* antovsky: The trouble with dividing by float(INT_MAX) is that it's biased
  towards some bit patterns (since INT_MAX can't be exactly expressed in
  float). This is easy to verify if you generate all valid float bit patterns
  between 0-1, and then check how many times the conversion hits each one. Sadly
  this "pedantic" conversion is a lot more expensive as you say, especially
  because the divide is required (multiply by 1.0/constant produces a slightly
  biased result as well).

How do you write a good integer hash function?
----------------------------------------------
The two approaches are: bitwise operations (add, xor, shift), and multiply by
primes. The bitwise approach is more widely discussed. Most of the attention
has been on optimizing for the CPU; I don't trust that the same algorithms
are fastest on GPU. Also, we don't need 32 high quality bits as output: we
only use the low order 23 bits. So testing is needed.

In http://www.azillionmonkeys.com/qed/hash.html, Paul Hsieh cites Bob Jenkins
<http://burtleburtle.net/bob/hash/doobs.html>, then builds a new hash function
that performs better on more modern hardware. Here's an excerpt from the end
of SuperFastHash that resembles the Alex Navaris hash:
    /* Force "avalanching" of final 127 bits */
    hash ^= hash << 3;
    hash += hash >> 5;
    hash ^= hash << 4;
    hash += hash >> 17;
    hash ^= hash << 25;
    hash += hash >> 6;
Here some 32-bit hash code from Bob Jenkins(2006), with instructions on how to
generalize it to a variety of situations:
    http://burtleburtle.net/bob/c/lookup3.c
Jenkins uses many bit rotate operations, which don't seem to exist on GPUs.
GPUs are in-order superscalar. We need to use SIMD instructions where possible.

Hasher API
----------
The general requirement is to take set of M 32 bit floats, and hash them onto
a set of N 32 bit floats in the range [0..1). For larger values of M and N,
we will be composing several primitive hash operations. Ultimately I'd like
to figure out a portable 'hasher' API, with multiple implementations offering
different speed/quality tradeoffs, which can be used as an optional parameter
to a noise function.

How do you test a hash function for making noise?
-------------------------------------------------
* Measuring speed.
* Measuring quality. See Marc Olano. Should be based on the degree of visual
  artifacts created in typical graphics workloads, since the criteria for
  cryptographic hashes are not relevant.

Nimitz: testing using ENT (http://www.fourmilab.ch/random/)

Octaviogood: a shadertoy for testing hashes:
https://www.shadertoy.com/view/wljXDz
