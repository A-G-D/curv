Abstract Arrays
===============
Data abstraction for lists & arrays:
 * lazy lists?
 * procedural arrays
 * typed arrays
 * sparse arrays

Concepts
--------
What is the pure functional analogue of C++ iterator concepts?
This would be a way of classifying arrays of values, at the highest level
of abstraction, based on how the data is accessed by algorithms.

A reified collection has all of its values laid out in memory at once.
Collections can also be procedurally generated, in a variety of ways, and
this also allows for infinite collections.

Ordered collections:

 Sequential: elements are accessed sequentially.
   Lazy list: corecursive codata: initial element v0 is the base case,
              v1 = f v0, v2 = f(f(v0)), etc.
   Compressed/variable length reified data, such as UTF-8.
   Supports sequential computation.

 Parallel: 'random access' elements, retrieved by index.
   Computed list: element v[i] is f(i).
   Reified array of fixed size elements.
   Supports data parallelism.

An ordered collection may be finite or infinite.

Multi-dimensional collection: index is a vector.
Computed, or a reified array.
 * nested or curried: vector elements applied one at a time
 * strict: vector index applied all at once (vector is a structure)

Labelled Tensors. Dimensions have names, rather than ordinals.
Easier to work with when using tensors with a large number of dimensions.
 * fetch an element: T{a:i,b:j}
 * `dim T`: {a:40,b:50}
 * `rank T`: 2 -- this implies that count{a:40,:50} == 2.
 * Reified or procedural.

How do Abstract Arrays interact with array-language semantics?

How do Abstract Arrays interact with Data Abstraction? The current proposal
is that an instance of an abstract data type is either a record or function,
it isn't a list or array.

Abstract Sparse Arrays
----------------------
https://github.com/yuanming-hu/taichi
http://taichi.graphics/wp-content/uploads/2019/09/taichi_lang.pdf

Taichi: A Language for High-Performance Computation on Spatially Sparse
Data Structures

* A struct-for loop iterates over all of the elements of a tensor.
  It is abstract: tensors may have many different representations.
  It is data parallel, and forms the body of a GPU compute kernel: one thread
  per tensor element.
  It will only iterate over active elements of a sparse tensor.
  This is the key to sparse computation.

* There is a language for defining hierarchical sparse data structures.
  It can describe VDB structures and many others.

3D visual computing data are often spatially sparse. To exploit such sparsity,
people have developed hierarchical sparse data structures, such as multi-level
sparse voxel grids, particles, and 3D hash tables. However, developing and
using these high-performance sparse data structures is challenging, due to
their intrinsic complexity and overhead. We propose Taichi, a new data-oriented
programming language for efficiently authoring, accessing,and maintaining such
data structures. The language offers a high-level, data structure-agnostic
interface for writing computation code. The user independently specifies
the data structure. We provide several elementary components with different
sparsity properties that can be arbitrarily composed to create a wide range
of multi-level sparse data structures. This decoupling of data structures from
computation makes it easy to experiment with different data structures without
changing computation code, and allows users to write computation as if they
are working with a dense array. Our compiler then uses the semantics of the
data structure and index analysis to automatically optimize for locality,
remove redundant operations for coherent accesses, maintain sparsity and
memory allocations, and generate efficient parallel and vectorized instructions
for CPUs and GPUs.

Our approach yields competitive performance on common computational kernels
such as stencil applications, neighbor lookups, and particle scattering. We
demonstrate our language by implementing simulation, rendering, and vision
tasks including a material point method simulation, finite element analysis,
a multigrid Poisson solver for pressure projection, volumetric path tracing,
and 3D convolution on sparse grids. Our computation-datastructure decoupling
allows us to quickly experiment with different data arrangements, and to
develop high-performance data structures tailored for specific computational
tasks. With 1/10th as many lines of code, we achieve 4.55Ã— higher performance
on average, compared to hand-optimized reference implementations.
