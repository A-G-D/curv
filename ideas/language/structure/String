From the perspective of Curv as an array language, is a string considered to
be an array, or a scalar?
 * In Curv 0.4, strings are halfway between scalars and arrays: some array
   operations work, some fail, and it's pretty arbitrary. That's not
   acceptable for an array language: I need consistency. Scalar or array?

Here are some approaches:

 1. A string is a scalar. 'String' is one of the 5 primitive data types.
    List operations don't work on strings. `strcat` concatenates strings:
    `concat` doesn't work. `strcat` doesn't obey strict list semantics, in
    the case where you are viewing a string as a list of EGCs, because two
    adjacent EGCs can merge into one during catenation. Three levels of
    increasing functionality:
     a. A string is an unintepreted blob. You can construct a string with
        a literal, you can concatenate, you can print, nothing else. You can't
        decompose a string. There is no string equality: comparing strings or
        using them as map keys is a code smell: use Symbols instead.
        Curv is not a string processing language.
     b. Equality (S1 == S2) follows Unicode semantics: two strings are equal
        if they normalize to the same sequence under NFC.
     c. If you want to view a string as a list of characters, then you must use
        an explicit conversion to a list of code points, or a list of extended
        grapheme clusters. A code point is an integer. An EGC could be
        represented as a string: I'm not sure we need a separate EGC type.

 2. A string is a list of characters. 'Char' is one of the 5 primitive data
    types, replacing 'String'. All list operations work as expected on strings,
    with no exceptions or limitations.
    
    Equality (S1 == S2) follows list semantics. Unicode string equality is
    provided by a separate string library. If you want to compare two *names*
    for equality using ==, or you want to use them as map keys, you should use
    Symbols instead.
    
    Strings are concatenated with `concat` or `++`, which use list semantics.
    Therefore, a character value is a unicode code point, not an EGC. (This
    is because two adjacent EGCs can merge during concatenation.) If you
    want to view a string as a sequence of EGCs, you use the string library,
    just as in approach #1.

    Heterogenous lists of characters and non-characters are supported, and will
    be used in the representation of rich text, when Curv becomes a visual
    programming language. Could introduce Racket/Scribble style markup as
    string escapes to embed rich text structures in strings.

    This approach has the best semantics: the most compatibility with
    equational reasoning.

    This approach complicates JSON export (`-o json` and `curvc`):
    we no longer distinguish "" and [], and "" is exported to JSON as [].
    Although you can currently use #'' to export an empty string.
    Curv v0.4 contains the JSON data model as a strict subset, allowing
    straightforward JSON import/export. With the introduction of symbols
    and especially with "string is a list of characters", the Curv data model
    no longer has a subset that is straightforwardly bijective with JSON.
     * Can use data patterns/schemas/specs to map between data models.
       Another example of moving complexity from one place to another.
     * Even with schemas, if there is a JSON value that can be either "" or []
       and the distinction is important, then how to we encode this?

 3. Typed lists. A string is a typed list of characters. "" != [].
    Apparently also [char #a] != "a" and map id "abc" != "abc"?
    This is compatible with JSON, but it opens a different can of worms.
    It is not compatible with the Compact Array proposal. It may be more
    compatible with the data models of other programming languages.

 4. A static type system like Haskell.

All dynamically typed approaches have the same technical power.

Approach #2 is easiest, if you are dealing with ASCII text, or with a subset
of Unicode where EGCs are code points. And that's 99% of the time. Outside of
that, if your code needs an EGC list, you must use more complex APIs.

All of the confusion and complexity comes from Unicode, and this can't be
eliminated, it can only be moved from one part of the language to another.

In approach #1, only a minimal set of string operations is provided in the core
language. All the Unicode complexity is quarantined in the string library.
So you need to climb the Unicode cliff to decompose a string, count the
characters. Which is fine if string manipulation is considered to be a low
level, tier 2 concern.

Approach #2 is consistent with pure functional and array languages.
Treating a string as a list of characters will be familiar to most users.
Symbols can fill the role of "scalar string values".
This is my current preference.

A String is a List of Characters
--------------------------------
In this section, I will consider that a string is a list of characters
(strings are arrays). This has benefits and drawbacks.

The benefits are:
* By considering a string to be a list of characters, we get simplicity and
  uniformity. All of the machinery for operating on arrays also operates on
  strings, with the same semantics as lists (no surprises as found in Curv 0.4).
* Since Curv is dynamically typed, this leads to heterogenous list of characters
  and non-characters, which can be used to represent rich text. A rich text
  data type is needed when Curv becomes a visual programming language.

The problems arise if Curv transitions from ASCII to Unicode:
* String equality uses list semantics, not Unicode semantics. Use symbols
  instead.
* String concatenation (via `concat` or `++`) uses list semantics.
  NFC is not preserved by list concatenation (use `strcat` instead).
* A character will be a Unicode code point. It is not an extended grapheme
  cluster (EGC), because:
  * The definition of EGC changes across Unicode releases. We don't want a
    valid character literal to become a syntax error due to a change in the
    Unicode standard, as happened to the Swift language.
  * String concatenation doesn't have array semantics if EGCs are characters.
    Two adjacent EGCs can merge on concatenation.

This design is consistent with the Compact Arrays proposal.
Specifically, there is only one abstract List type. A list of numbers
and a list of characters can be concatenated (you don't get a type error).
There is only one empty list value: `[]`, which means that `""` is syntactic
sugar for `[]. Internally, there are multiple list representations specialized
for holding different types of scalars, but this is a performance optimization
that doesn't complicate the Tier 1 semantics.

There are no character literals, we use function calls: `char 97 == char #a`.
Alternate designs for character literals look weird: #"a", #|a| and #<a>.

`[char #a, char #b, char #c] == "abc"`
    These two expressions evaluate to the same value, and both print as `"abc"`.

`"" == []`
    A string is nothing more than a list of characters. The empty string is
    the same value as the empty list. An empty string prints as `[]`.
    `is_string []` is true.

String equality is list equality.
    Two strings are equal if they consist of the same sequence of characters.
    This works great for ASCII. However, by identifying characters with code
    points, we get the result that two strings that differ only in their
    normalization form compare unequal with respect to `==`. You need Unicode
    equality semantics when comparing two names for equality, but to represent
    names you should use symbols, which have these equality semantics.
    Alternatively, we can have additional Unicode operations in a string
    library, and maybe there is a `strequal` function.

By considering a string to be a list of characters, we get simplicity and
uniformity. All of the machinery for operating on arrays also operates on
strings, with the same semantics as lists (no surprises as found in Curv 0.4).

`count S`
    If S is a string, then `count S` is the number of characters in the string.

`[for (c in S) c]`
    If S is a string, then this evaluates to the string S. This is useful for
    generic programming. However, note that in Unicode, there aren't a lot of
    high level operations on Unicode code points. There is equality. There is
    conversion between integer and character. Each code point has a set of
    properties, but it's mostly low level technical stuff. Conversion between
    lower and upper case can't be done at the code point level, for example,
    unlike in ASCII. If Curv ever needs to support unicode string processing,
    it will need a separate string library that applies Unicode semantics to
    Curv string values.

++ is the infix concatenate operator.
[0,1]++[2,3] prints as [0,1,2,3].
"ab"++"cd" prints as "abcd".
"ab"++[2,3] prints as "ab"++[2,3].

Heterogenous lists of characters and other values may be a useful representation
for rich text (eg, like markdown text). I'll need a representation of rich text
when Curv becomes a visual programming language.

strcat and string
-----------------
Historically, `strcat` had two functions: to concatenate strings (you could
not use `concat`), and to convert values to strings.

In the new design, these functions are separated into two orthogonal bindings.
`concat` concatenates a list of strings, and `string` converts an arbitrary
value to a string. `strcat(L)` is replaced by `concat(map string L)`.

A ${expr} string substitution is replaced by string(expr).

`string` fits in to a larger pattern of value constructor/predicate functions:
    string      is_string   -- string converts arbitrary value, not vectorized
    symbol      is_symbol   -- symbol converts a string or value, not vectorized
    bool        is_bool     -- bool converts 0/1 to false/true, is vectorized
    char        is_char     -- char converts scalar to char, is vectorized

`string` is idempotent. Should the other constructors be idempotent?
Maybe: it fits with a model of types as idempotent constructor functions,
and it fits with the proposed `pat >> ctor` pattern type.
Eg, then bool(symbol(S)) converts a string to a bool, with an error if S is
not "true" or "false".
But, that example could also be written as `symbol S :: is_bool`.

This larger design has implications for the `char` constructor:
    char (C :: is_char) = C
    char (N :: is_nat) = convert code point to character
    char (S :: is_symbol) = convert single-character symbol to char

string V
    if V is a string, return V.
    if V is a char, return [V].
    if V is a symbol, return the name of V as a string, without # or quotes.
    if V is a general list, then maximal contiguous sublists of non-characters
        are printed as lists using `repr`, with leading and trailing [ ]
        and commas separating the values. Any characters in between these
        non-character values are represented as themselves, without quotation.
    Otherwise, return `repr V`.

++ vs &
-------
An alternate syntax idea:
 * Use `&` as the infix concatenation operator.
 * Use `&` instead of `$` as the string escape prefix.
Then, "f("&a&")="&b is abbreviated as
      "f(&a)=&b"
This is "notation as a tool of thought" territory: the short form is derived
from the long form by omitting characters, in a kind of algebraic manipulation.

Character Constructors
----------------------
Here we consider syntax for character literals. All the alternatives will look
weird to most people, since the popular 'a' syntax is not available. We need
a `char` constructor function regardless, and Curv is not a text processing
language, so I currently plan to not implement character literals, and see
how usable that is.

With Unicode, a character literal can contain two or more code points,
if that sequence of code points normalizes to a single code point in NFC.
This is safe, because NFC is guaranteed to be stable across Unicode versions:
http://www.unicode.org/reports/tr15/#Stability_of_Normalized_Forms
[Curv source code is converted to NFC before being parsed.]

With Unicode, the syntax for a character literal needs a leading and trailing
delimiter. If the 'character' being quoted is a "combining character", then
it may be rendered above or below one of the delimiters.
The syntax used by Lisp and Scheme (`#\a`) is not suitable.

#|a|  [#|a|,#|b|]   // harder to type, easier to read?
#"a"  [#"a",#"b"]
#<a>  [#<a>,#<b>]
#`a`  [#`a`,#`b`]

#| |, #|!|, #|"|, #|#|, #|$|, #|%|, #|&|, #|'|, 
#|(|, #|)|, #|*|, #|+|, #|,|, #|-|, #|.|, #|/|, 
#|0|, #|1|, #|2|, #|3|, #|4|, #|5|, #|6|, #|7|, 

#" ", #"!", #""", #"#", #"$", #"%", #"&", #"'", 
#"(", #")", #"*", #"+", #",", #"-", #".", #"/", 
#"0", #"1", #"2", #"3", #"4", #"5", #"6", #"7", 

#< >, #<!>, #<">, #<#>, #<$>, #<%>, #<&>, #<'>, 
#<(>, #<)>, #<*>, #<+>, #<,>, #<->, #<.>, #</>, 
#<0>, #<1>, #<2>, #<3>, #<4>, #<5>, #<6>, #<7>, 

The #<x> syntax is less ambiguous in the case of #<#> vs #|#|.
See also #<<> #<>> vs #|<| #|>| #|||.

The #<x> syntax might look better if x is a combining character which is
rendered above or below one of the delimiters?

 !"#$%&'
()*+,-./
01234567

Should there be a kind of character literal containing a numeric escape
sequence, similar to C's `'\1'`? Or should we use `char 1` instead?
I prefer the latter, because it is more general: the argument can be an
arbitrary expression. The numeric escape syntax is not just duplicate
functionality, but it is also a syntax that is not composable.

char 97         =>  #|a|
char[97,98,99]  =>  "abc"

ucode #|a|   => 97
ucode "abc"  => [97,98,99]

Control characters (like newline) print as `char 10`.
Printable characters print as `#|a|`.

The boolean equivalents of `char` and `ucode` are `bool` and `bit`.

No Special Syntax for Character Literals
----------------------------------------
Instead we construct character values using a function call.
    char 97
    char #a
    char #'>'

>>> "abc"[0]
char #a

With no character literal syntax, how do you pattern match a character?
Using `== expression` patterns.
    match [
        == char #a -> 
        == char 127 ->
        == nl ->
        ]

So, a string literal "abc" is sugar for [char #a, char #b, char #c],
hence symbols are a more fundamental concept than characters or strings.

Every character literal is a call to 'char'.
 * This is a uniform syntax.
 * It is reasonably obvious what the syntax means (we are constructing
   a character). You can look up the meaning of 'char' if it isn't clear.
   With any of my weird bespoke character literal syntaxes, the meaning is
   less clear.
 * It is a composable syntax. A numeric argument can be replaced with a
   more complex expression. Can't do that with a numeric escape sequence
   inside a C character literal.
 * We need the `char` function anyway, so there is less duplication
   of syntax/concepts.
 * In the future, there will be many more abstract data types whose
   constructors and print-syntax are function calls.

Compact String Representation
-----------------------------
A Char value has a 64 bit pointerless NaN boxed representation.
The most general representation of a string is a list of boxed characters.
We can keep the compact curv::String representation, to be generated by
string literals and `strcat`.

So that means we may need to convert a compact string to a general list,
which requires 64 bits per character.
Eg,
    concat("abc"/*compact*/,[1,2,3]/*general*/) => a general list
Eg,
    local s = "abc";    // s has compact representation
    s[1] := 17;         // s converted to general representation
    print s;
    // "a"++[1]++"c"

A more sophisticated "general list" representation would allow lists to be
represented as trees, eg similar to the "rope" representation of strings.
I won't attempt this just yet, as it complicates the implementation further.

The "efficient array" proposal will provide a mechanism for directly
constructing compact strings (ASCII or UTF-8) in the general case.

Characters are Symbols
----------------------
Instead of introducing a distinct character type, and a distinct syntax
for character literals, we could define a character value to be a symbol
whose name is a single character.

"abc" == [#a,#b,#c]
is_symbol(#a) == #true
is_char(#a) == #true

It is already the case that "${#a}" == "a".

So there are actually 4 fundamental data types: symbol, number, list, record.

Any downside?
* You probably don't want to use single-character symbols for many uses
  outside of characters, unless you want [#x,#y,#z] to print as "xyz".
* `fields{d:1,height:3}` returns "d"++[#height].
* This requires the existence of symbols containing non-printable characters,
  which opens a (small) can of worms.

Nah, maybe not.

Other Character Literal Syntaxes
--------------------------------
$a  $' '
\a          Clojure
#\a         Lisp, Scheme
(string-to-char "a")    Emacs Lisp
$a  $\n     Erlang
#"a"        Standard ML, Red
Character("a")    Swift
