TODO:
 * value_at(): fully support reactive values (both list and index position)
 * A[i,j,k] := ... in full generality
 * unit tests for the above

How to construct a reactive vec2 from a reactive num (unit testing):
  let v=if (time==time) [time,time] else [0,0] in v

Weird Idea:
  x.f is alt syntax for f x.
  #foo {foo:1} => 1 -- a symbol is a Lens function that extracts a record field
    Like Clojure and maybe some other languages.
  R.#foo extracts a field from a record.
  0 [2,3,4] => 2 -- a nat is a Lens function that extracts a list element
  L.0 is the first element of a list.
  [f,g] x => [f x,g x] -- list of functions is an Atlas (Nial) or a Construction
    Functional in FP. Except it is a Lens if the elements are Lenses.
  vec.[X,Y] swizzles a vector
  x>>slice[f1,f2] is the slice operator, like x.[f1,f2]

  precedence of '.':
   1. x.f y <=> f x y
      For the shape library, this means shape.move[1,0,0] <=> move shape [1,0,0]
      So the left arg is inserted as the first function arg,
      similar to Python method invocation or Clojure pipeline syntax.
      It works well for autocomplete of x.? since you look for functions that
      accept an x as their first argument.
   2. x.f y <=> f y x
      This is patterned after the >> operator.

New Design:
  locatives:
    expr.[i] indexes a list or a record
      list.[i] -- i is a nat, list of nat, record of nat, or tree of same
      rec.[i] -- i is a sym, list of sym, record of sym, or tree of same
        eg, {a:1,b:2,c:3}.[{a:#a,b:#b}] => {a:1,b:2}
      K9 also supports 'record of index' in the index function.
      However, K9 does not generally vectorize over record values,
      Eg, [a:1]+[a:2] is an error. Although this works in K7.
    expr.[i,j,k] slices a tree of lists & records along multiple dimensions
    expr.name -- NOT left-vectorized: same as expr.[#name]
  defined(expr.name) -- NOT left-vectorized, that would be inconsistent
                        with expr.name
  defines[record, symbol] -- 'defines' is just an ordinary function,
                              both args are scalar, can be fully vectorized.
  fields(record) -- arg is scalar, can be vectorized -- DONE
   
Design:
  locatives:
     expr[i,j,k]
     expr.name -- left-vectorized
     expr@primary -- rec@sym, left-vectorized, replacing rec."$sym"
   defined(expr.name) -- left-vectorized
   defined(expr@primary)
   deprecate rec."$sym" -- replaced by rec@(Symbol "$sym")
   Symbol str
Notes,
 * struct@key bugs me.
    * Use is rare for records: only if key is computed, not constant.
    * More important for dicts. A dict can also be indexed using 'D key', but
      that is not a locative and can't be left-vectorized.
    * Problem: multiple syntaxes for the same operation.
    * Could be replaced by struct.(key) -- makes more sense for records,
      maybe less sense for dicts.
    * Some other languages use the same operation for indexing a list and
      indexing a dict: S[i].
   But: just consider lists and records.
    * I need an operator for extracting a field from a record, given a symbol
      expression.
    * I cannot use rec[#foo] because it conflicts with rec.call.
    * This operator needs to be left-vectorized, unlike list indexing.
      It's a consequence of Curv being an array language.
    * `rec@key` is perfect. The alternative is to kick this upstairs to the
      Lens API: 'rec>>at key' and 'rec>>at key .put x'.
            or: 'rec>>#foo' and 'rec>>#foo .put x'
 * Mixed case for `Symbol` bugs me. But see language/types/Types. This design
   is just like Swift, it is a reasonable syntax.
More thoughts:
 * `struct!indexlist` is a structure slice: works on arbitrary nested lists
   and records. It provides polymorphic indexing for lists and records,
   eg list![0] and record![#foo]. It is a locative. It subsumes list[0] and
   rec@#foo.
 * An alt syntax is postfix.primary where primary is not an identifier.
   This would include list.[0], record.[#foo]. You could use struct.(list).
    * May be easier to decode for first time users. The '.' operator is used
      for all structure indexing, with s.foo being a special case.
    * F# uses array.[0] for array indexing.
    * Meaning of x.y changes to x.[#y] -- no left vectorization.
      Could instead use list.[..,#foo] to extract column from list of records,
      similar to list.[..,i] to extract column from matrix.

Implementation Ideas
--------------------
Analyse a postfix phrase as a Locative, regardless of context.
That will require a lot of refactoring. Not worthwhile.

As today, only analyse a phrase as a Locative on the left side of ':='.

Implementation
--------------
old:
  void Assignment_Action::exec(Frame& f, Executor&) const
    { locative_->store(f, *expr_); }
  Locative -- it's an AST with the arrows pointing down toward the leaves
  Local_Locative    // local variable
  Dot_Locative      // x.s
  Indexed_Locative  // x i
new:
  Need a path that can be traversed from the leaf out to the top level and
  contains the index values. The old Locative AST is backwards.
   * Linked list of Dot_Index, Bang_Index and Call_Index, both contain index
     value and next. Construct linked list while traversing Locative tree.
     Dot_Index contains Symbol_Ref, Bang_Index and Call_Index contain Value.
     Path iterator contains Index ptr, Index type, position in Call_Index path
     if the Call_Index is indexing a list, rather than a dict.
      * There is a design alternative where S I := X is not legal when S is a
        Dict, and you must use S!I := X instead. In that case Call_Index
        contains a Shared<const List>.
  This design is tightly linked to the (somewhat arbitrary) indexing syntax
  I chose. That's okay for a purely internal API. However, there is also a
  proposal for a Curv API for traversing a data structure using a path. How
  are the two related and do they share code? A simple path-based Curv API
  would just use a list of index values, without partitioning the list into
  call/dot/bang segments and type-checking each segment.
new:
  A Lens takes a structure and: returns a substructure (get); or: sets that
  substructure to a specified value (put). We can convert _[i,j] and _.foo
  locatives into lenses.

Assignment to an Array Slice
----------------------------
(It would be more accurate to call this "tree slicing", since this works on
jagged, non-rectangular arrays.)

A primary goal is to support GLSL swizzle semantics. In SubCurv,
   A[[X,X,Y]] is a legal rvalue. Note, duplicate indices.
   A[[Z,X]] is a legal rvalue. Note, non-contiguous slice, indices are not
   required to be in ascending order.
Vector slices are also assignable. For a constant index vector, duplicate
index values are not allowed. For a runtime index vector, duplicate index
values can't be excluded, so updates are processed left to right, and the
last assignment wins.

In Python, a list slice that denotes a contiguous subsequence, with indices in
ascending order, can be replaced by a new sublist with a different length.
If the index value (range) is not contiguous or not ascending, this is an error.
In SubCurv, you can't change the size of an array at runtime, and we report this
at compile time. We don't support this in Curv, it's not an important use case.
It's an error in K.

We will use K assignment semantics. It's a generalization of the semantics we
need for GLSL, and it works on arbitrary trees.
 * An index tree can contain multiple instances of the same index number.
   We update indexed locations depth first, left to right, and the last update
   wins.
 * You can't change the shape of a tree (in the sense of Python).

In `A[Ix] := B`,
  Ix is an index value: a tree of Nats, where each Nat < count A.
  We traverse `Ix` depth first, left to right, and for each Nat `i` in Ix,
  we update A!i with the corresponding element of B, which has the same shape
  as Ix.

`A x .y z := B` is internally equivalent to
   A := A >> update [x, #y, z] B
so I need to define how ternary update works. I think the full path after A
needs to be a data structure traversed at runtime. For the purposes of this
internal primitive, I think it makes sense to flatten the path into
   x ++ [#y] ++ z
The path is a list of index values.

update [] B A => B
For a non-empty path whose head is index value Ix and whose tail is P,
  If A is a list, Ix is a Nat or a tree of Nats.
  If A is a record, Ix is a Symbol or a tree of Symbols.
  Traverse `Ix` depth first, left to right, and for each scalar `i` in Ix,
    Select E, the corresponding element of B, which has the same shape as Ix.
    Update A!i with: update P E (A!i)
  Return the updated value of A.

Generalized Array Slicing
-------------------------
A[i,j,k]
Current semantics are the same as K's A[i;j;k], supports jagged arrays.
Indexing with a path is an operation on trees:
  i is a tree of natural numbers, each in the range 0..<count A
  for each n in i, replace it with A!n[j,k].
  Base case: A[] => A.
  So this is a recursive operation.

What I don't currently support:
 * negative indices, slice notation with negative indices (Python, Mathematica)
 * special index range notation, eg: `..`, `A..`, `..B` (Python, Mathematica)
   In K, `..` is specified by an empty argument, eg A[i;;k]
These notations are useful when the end of a range index is relative to the
size of that dimension. Right now you need to use `count A`, `count(A[0])`,
`count(A[0,0])` etc to compute the end of a range.

I could leverage the reactive variables mechanism and introduce an 'end'
variable that only has a value in an indexing context. Then,
    `..`  is `0..end`
    `A..` is `A..end`
    `..B` is `0..B`
No need for negative indices, you can write `end-2` or whatever.

Awkward Arrays supports a much fancier design for array slicing.
It's also a complicated mess, but there might be good ideas to copy.
https://github.com/scikit-hep/awkward-array#slicing-with-square-brackets

Awkward allows indexing using a boolean list. APL supports this using a
separate compress verb, and K has a where verb that converts a boolean list
to an index list. K's `where` verb replaces a multiplicity of APL verbs.
