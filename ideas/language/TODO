# TODO: Language Changes

High:
* vectorized boolean operations: for noise, and colour conversion
* V[[X,Y]] := vec2 in Curv, SubCurv
* M[i,j] := a
* replace foo."bar" with
  * foo!#bar, foo!#bar := newval, defined(foo!#bar)
  * foo >> at[#bar]
    foo >> at[#bar] := newval ?
    defined(foo >> at[#bar]) ?
    This is okay as a replacement for `!`, if dictionaries are distinct
    from modules and support dict[key] syntax.
  * fetch [i1,i2,i3] S, amend path newvalue S
* replace {"foo":bar} with {#foo => bar}.
* {pattern : value}
* Multipart function definitions, allows recursive piecewise functions,
  which are wanted for lib.noise. OR: `match` is a keyword, see Match.
* Picker predicates: implement the complete set

Medium:
* Get rid of `where`, just use `let` (simplification)
* Branded values?
* `== value` is a predicate, and it is an equality pattern.
* Use _ as digit separator in numerals.
* any, all

Low:
* Disallow actions in a `let` clause. However, there's a use case for
  assertions in a scoped record constructor. Let's see how record literals
  evolve.
* mixed a=/a: record literals
* Issue #50: unintuitive operator precedence. My proposed solutions:
  * warn about inconsistent white space in expressions, eg: 'f -1' or 'f a.b'
  * Lua-like function call syntax. 'f 1' and 'f a' no longer supported,
    but 'f(x)', 'f[x]' and 'f{a:b}' are still supported.
* missing features: Str[i] := c, for (c in Str)

Breaking changes:
* file.foo and package. Remove 'file pathname'.
* function/record equivalence
  * primitive functions have a 'call' field, support 'fields' and 'defined'
    and 'f.call' and 'include' and '...'.
  * 'is_record f' is true
  * 'is_fun r' is true if r is a record with a call field.
    is_fun x = defined(x.call);

Extensions:
* std
* compose -- function composition. Short form is 'co'?
  x >> compose[f,g,h] means x>>f>>g>>h ?
  * The function returned by compose reports a pattern match failure if any
    of the constituent functions reports a pattern match failure. This is
    important for `match` and *cast* patterns.
  * This means that several of the constituent functions are called before a
    pattern match failure is detected. Is that okay?
* Record constructors may combine definitions and field generators.
  Shorter definitions for shape constructors with .mitred/.exact members.

## Terse Function Literals
For function literals with a single argument, and a short body (suggested max 12
characters),
    (_+1) is an abbreviation of (x->x+1)
Inside of a parenthesized expression, `_` is an implicit function parameter.
Doesn't work if the parameter is used inside nested parens, but does work if the
parameter is used inside of [] or {}. Should not be used for large functions
for style reasons.

## Quoted Identifiers and DFNs (Dynamic Field Names)
### Quoted Identifiers
`'hello world'` is a quoted identifier.
It can be useful in the following contexts:
 0. Reserved words become available as identifiers, eg 'if' or '_'.
 1. As a fluent parameter name for a parametric shape.
    The name appears in the GUI.
 2. `foo.'hello world'`, as an alternative to `foo."hello world"`.
 3. `{'hello world':value}`, as an alternative to `{"hello world":value}`.
 4. In the Cue language, a field definition whose name begins with _ is
    private, unless the name is quoted.

It bothers me that double-quoted-strings have two meanings, depending
on context: either an identifier (cases 2 & 3), or a string literal.
So quoted identifiers are a path to fixing this.

### Dynamic Field Name Syntax
There are two use cases for the `{"hello world":value}` syntax.
* Non-standard field names (containing spaces, punctuation).
  For this use case, each name is static. Quoted identifiers are a
  more general solution than the quoted string syntax, because they can be
  used in complex patterns. Eg, `{('nsi-1','nsi-2'):value}`.
* Dynamic field names. Quoted strings are the current syntax for a DFN
  in a field generator, because you can use "$var" as a DFN.
  The syntax for a field generator is:
    field_generator ::= DFN : expr | pattern : expr
  That is, only one DFN per field generator.

I considered using `'$var'` as the syntax for a DFN, but this creates confusion:
in what contexts is it legal to put a dynamic $var subsitution inside a quoted
identifier? This source of confusion goes away if the syntax for a quoted
identifier and a DFN are clearly distinct.

An alternate syntax for DFNs: `$<primary_expr>`.
    foo.$var
    {$var : value}
    if (defined (foo.$var)) ...
This echoes the proposed syntax for string-valued options: -Ofoo='$var'.
We could combine this proposal with the static quoted identifier proposal.
Or, note that `$"hello world"` is legal syntax for a dynamic field name.

Comparison to other programming languages:
    `foo[fieldname]` in Javascript, Python, etc,
    vs `foo.$fieldname` in this proposal,
    vs `foo."$fieldname"` in original Curv.

However, the current DFN syntax is mostly backwards compatible with JSON,
modulo $ and \ escapes, which is kind of cool.

### Map Syntax
Instead of overloading the `:` statement with either a pattern or DFN as
left argument, the "maps and symbols" proposal adds a Map data type,
and defines a Record as a Map where all the keys are symbols. There is new
syntax for Map literals:
    {key1=>value1, key2=>value2, ...}
and so you can write:
    {#foo=>value1, #bar=>value2}
as equivalent to {foo:value1, bar:value2}.

Instead of DFNs for field selection, provide a new operation for selecting
a map element using a key. Maybe bring back the `structure'key` operation
in some form (structure is a list, record or map). Seems like I'll need `'`
for quoted identifiers, so why not `!`.
    foo.bar
    foo!#bar

## Definition as a Block Body

A definition should be legal as the body of a `let` or `where` phrase.
I am particular interested in this case:
    f pattern =
        ...
    where
        ...
This allows subexpressions in patterns on the left side of the `=`
to be in the scope of the `where` clause.

## Patterns

New New Pattern Design:
* `val :: predicate` is a predicate assertion expression,
  which aborts if `predicate val` is false, otherwise returns val.
* `pat :: predicate` is a predicate assertion pattern,
  which fails if `predicate val` is false, otherwise matches pat.
* `pat >> cast` is the new syntax for a cast pattern.
  Note that `pat :: predicate` is equivalent to `pat >> ensure predicate`.
  Note that >> is left associative, so `pat >> f1 >> f2` is equivalent to
  `(pat >> f1) >> f2`, which should work. Fixes bug in previous cast syntax.
* The `pat == val` syntax is consistent with the previous two.
  * Um, there's little point in binding a variable after a successful equality
    test. Why not just `== val`? For other relational ops, it makes more sense.
  In all three cases, you have variable names lining up in a column on the left.

Equality Patterns:
A 'equality pattern' tests if the value to be matched is equal to a specific
value. Useful for simulating C switch statements (using `match`).
Useful for matching nilary constructors (when simulating algebraic types).
I have considered several alternate proposals:
* `== value`
  * Works for any value.
  * Sections: This syntax could also be used as a 'section' of the equality
    operator. Eg, `filter(==0)`.
  * This is consistent with another right section proposal: "`f` x".
  * Which leads to range patterns. Suppose we add elem(val,list).
    And we add `f` x as a pattern. Then `elem` 1..10 is a range pattern.
* Literal constant patterns. (Haskell has them.)
  * #true, #false, #null are literals for true, false, null. (Done.)
  * Negative numbers and infinity?
    * `-<numeral>` and `+<numeral>` are patterns.
    * There is a <numeral> for infinity.
      * `inf` is a keyword. Simplest and best solution.
      * Use some other special syntax like `0inf` or `inf.0`.
        SFRI-70 uses `+inf.0` and `-inf.0` as infinite numerals.
        Clojure uses ##Inf and ##-Inf.
      * I don't like `#inf`, I think that Symbol and Number types are disjoint.
  * String patterns currently conflict with "name":value field constructors.
    * The Map proposal defines a Record as a Map where the keys are Symbols.
      A record may be written as {#foo=>1, #bar=>2}. The `:` statement is no
      longer overloaded, it's just `pattern:expr`.
    * The DFN proposal is `$foo:value` for dynamic field names.
    * Replace "name":value and foo."name" syntax with quoted identifier syntax:
      'name':value and foo.'name'. Doesn't support dynamic field names. (Done.)
    * String literal patterns must be parenthesized in situations where they
      are ambiguous, such as `("foo"):value`.
    * The Symbol proposal claims that string patterns aren't needed. If this
      need arises, you should be using symbols instead.
Yes to `== value` patterns. No to literal constant patterns.
  match [
    == 0 -> case zero;
    == 1 -> case one;
  ]
  f (== 0) = case zero;
  f (== 1) = case one;

New Pattern Types:
* '<pattern> if <condition>' -- conditional pattern. The pattern is matched,
  variables are bound, then the condition is evaluated over the bound variables,
  and the match fails if the condition is false.
  * I might prefer '<pattern> when <condition>' for better readability.
    (Not confusible with an 'if' expression when quickly scanning code.)
  * The 'phrase abstraction' design pattern asks if the syntax for this should
    actually be 'if (condition) pattern'? But the C if syntax is
    counterintuitive because the pattern binds variables in the condition.
  * Also, should we have 'statement if condition'?
* 'pat1 && pat2' -- and pattern. The same value matches both patterns.
  * bound variables are disjoint between pat1 and pat2.
  * Idiom: 'id && pat' is like 'id@pat' in Haskell.
* 'pat1 || pat2' -- or pattern. The value matches either pat1 or pat2.
  * pat1 and pat2 define identical sets of bound variables.
  * Useful when simulating a switch statement (one case matching 2 values).
  * [x,y] || [x,y,_==0]
  * Rust, F# use 'pat1|pat2' -- looks nice in switch.
* 'pat >> cast' -- cast pattern.
  * If V is the value being matched, then we evaluate `cast V`.
    If cast's parameter pattern fails, the match fails.
    If the body of cast aborts, then the program aborts.
    Otherwise, the result of `cast V` becomes the new value
    that is matched against `pat`.
  * A cast is a function that maps values onto a particular type, and is
    idempotent for members of that type. This feature implements implicit
    conversions to a type.
  * Within the cast function, the parameter pattern match fails for values that
    are clearly not a member of the type. For values that are considered
    corrupted instances of the type, the parameter matches but an assertion
    fails, aborting the program.
  * S.P.Jones uses the term 'transformational pattern' (pat!fun), and shows
    that this is a way to reconcile pattern matching with data abstraction.
    The cast fun transforms an ADT to a pattern matchable value.
  * `pat >> cast1 >> cast2` equals `(pat >> cast1) >> cast2`.
  * Which equals `pat >> compose[cast1,cast2]`, but only if the result of
    `compose` reports a pattern match failure if any of the constituent
    functions have a pattern match failure.
* Variations of predicate patterns:
  * 'pat == expr', 'pat != expr', 'pat < expr', ... -- relational op predicates
  * 'pat `elem` listexpr' -- range patterns, like 'x `elem` 1..10'.
  * Equality patterns, `== expr`, see above.

"Pattern Guards and Transformational Patterns", Simon Peyton Jones

If Pattern Matches Expression Then ...:
`if (pat <- expr) stmt1`
`if (pat <- expr) stmt1 else stmt2`
`<-` is pronounced "matches". `pat<-expr` is a pattern matching phrase,
which either succeeds (and binds some identifiers) or fails.
The bindings from pat are visible in stmt1.
There are compound PM phrases:
  PM ::= pat <- expr
  PM ::= PM1 && PM2 | PM1 && expr | expr && PM2
         // PM1 and PM2 must define disjoint bindings.
         // PM1 bindings are visible in PM2 and in expr.
         // 'expr' is equivalent to the PM '_ if expr <- null'.
  PM ::= PM1 || PM2
         // PM1 and PM2 must define coincident bindings.
         // PM || expr isn't legal because bindings from PM aren't
         // initialized if PM fails.

Guarded Expressions:
* Inspired by Haskell 2010 guarded equations, but more general.
* A 'guarded expression' is an expression that either yields a value or fails
  due to pattern match failure.
* If the body of a function is a guarded expression GE, then pattern
  match failure of the GE is pattern match failure of the function.
* `try function_call`
  `try function_call else expression`
  Eg, `try arg >> pat->result` is like: `if (pat <- arg) result`.
  `try` can be used to classify function arguments based on their parameter
  patterns.
* Syntax:
  GE ::= if (...) expr
       | if (...) GE
       | if (...) GE else GE
       | try expr
       | try expr else GE
       | expr
* Used with if(pat<-expr)...
* PM ::= pat <- GE
  PM fails if GE fails.
  Eg, if (r <- try f x) <do something with r if f x succeeds>

Filtered For Loop:
* Haskell: for (pattern in list) ..., list elements not matching pattern
  are skipped. Convenient in some cases, hides coding errors in others.
  Swift also has a syntax for this.
* In Curv, we can use
    for (x in list) if (pattern <- x) ...
  This is simple, and makes it obvious that filtering is happening.
* We could also incorporate the filtering into the for loop.
  I don't think it should happen by default, but maybe an alternate syntax:
    for (pattern <- list) ...
  Low priority, not clear we require such an abbreviation if the previous
  syntax is available.

I now have a general notion of a function call failing due to a domain
error, and the ability to direct evaluation based on this failure.
It reminds me of:
* "Goal directed evaluation" in Icon, with 'PM' expressions that
  behave like boolean conditions that can be combined with && and ||.
  Although that is supposed to also cover the generation of a stream of results,
  and backtracking on failure.
* Exception handling, although this particular variety is restricted so that
  it does not break referential transparency.

This is now very general. "pattern directed evaluation"

## Type Classes:
We can define a 'type class' as a record containing a 'call' function
(a type predicate), plus constructors (eg 'make')
and operations on type instances. Eg,
    BBox = {
        call = ...;
        union = ...;
        intersection = ...;
    };
If multiple classes implement the same protocol, then we have the effect of
Haskell type classes. A class needs to be passed as an explicit argument.
    f T (T x) = ...

## Tensors
* rank t
* dimension t -- vector of dimensions of tensor t.

Tensor version of `map` or `for`, for tensorizing an operation.
Works on scalar (rank 0) operations, but also works on operations
with a well defined rank > 0. Eg, `phase` is a rank 1 operation.
* Something like:
    phase = tensor_map ((is_vec2 p)->atan2(p[Y],p[X]))
  to define a tensorized `phase` operation.
* Possible definition:
    tensor_map f =
      match[
        f,
        (is_list x)->[for (e in x) tensor_map f e],
      ];

Indexing:
* a[i] := item, i is an integer
* s.key := item
* remove a'b ?

List Slices:
`a[i..<count a]` is inconvenient, repeats `a`. Fix?
* Maybe a[...] is a special syntactic context, in which:
  * a[..j] and a[i..] are special abbreviations.
  * `end` is bound to index of final element, like MatLab.
    So a[i..end]
* Maybe `i..` is an infinite range value, can be used to slice a list.
  Short for `i..inf`. `count(i..)==inf`.
* `take n list` and `drop n list` for +ve and -ve n.
* Can't support Python negative indexes (-1 indexes the last element)
  because [0..count a - 1] is a list of the indexes of a, even if a is empty,
  meaning that [0..-1] denotes [].

Multidimensional array slicing a[i,j,k].
`a` is rectangular array of dimension `d`, or tree of max depth `d`.
Currently: Non-final indexes must be integers. Final index can be a tree.
Works on trees.

List Slice Assignment:
* `v[[X,Z]] := v2`, similar to GLSL vector swizzle assignment.
  Source and destination lists have the same count.
* a[i..j] := list. In a range slice assignment,
  source and destination lists can have different counts.
* Generalized `a[list1] := list2`. list1 and list2 can have different counts.
  If list1 is shorter, extra elements at end of list2 are appended to final
  element indexed by list1.
  If list1 is longer, extra elements indexed by list1 are deleted.

Multidimensional Array Slice Assignment `a[i,j,k] := x`.
`a` is rectangular array of dimension `d`, or tree of max depth `d`.
* All indices are integers. Easy, works for trees.
* `a` is an array, all indices are arrays. As in APL.
  What happens if the same element is indexed twice? What's the new value?

## Debug actions:
* print_timing(string,expr), returns value of expr
* `debug identifier action` -- locally bind identifier in the scope of action
  to a debug object, used to query and modify the state of the debugger.
  This is a generalized debugger interface, which doesn't let debugger data
  or shared mutable state escape into the model. The debug object is a record,
  the individual named objects are perhaps top level bindings in the CLI when
  interacting with the debugger.
* `exec(expr)`: evaluate an expression for its side effects, discard results.
  `_=expr` could be an alternative (see _ pattern), but might be optimized away.
  * exec(file "unit_test.curv");
  * exec(print_timing("msg",expr));
* `enter_debugger`, aka `debug`
* assert_error(errorMessageString, expression)

## Generalized Definitions:
* `include {module}`
  Could be used to embed sequential bindings in a recursive scope, or v.v.?
  Could be useful in abstract evaluation where the {module} argument is
  unwrapped during abstract evaluation? Dunno.
  `include {module} where (localDefinitions)`? Information hiding, in lieu of
  private module members.
  With the proposed compile type type inference system, `include` could accept
  any argument with type Record.
* `if (cond) (a=foo;b=bar) else (a=bar;b=foo)`
* `def where bindings`, let bindings in def`.
  Could be used to embed sequential bindings in a recursive scope, or v.v.
  Information hiding, in lieu of private module members.

## Lexical:
* unicode operators (needs re2c or Ragel)
    90° == 90*deg
    ≤ ≥ ≠
    ¬a == !a
    a·b == dot(a,b)
    a×b == a*b or maybe cross(a,b)
    a÷b
    √a
    a∧b == a&&b
    a∨b == a||b
    x→x+1   ==   x->x+1
    for (i ∈ 1..10)
    π == pi
    τ == tau
    ∞ == inf
    x↑y = x^y
    “foo” == "foo"  -- note, resistant to systems that autocorrect "" to “”
    g∘f == compose[g,f]
    1.0₁₀3 == 1.0e3 -- not seriously, though.
  The problem with Unicode characters is the difficulty of typing them.
  I'd like to see a cross platform solution for typing Unicode technical
  characters using standardized mneumonics: eg, 'Compose <=' gives ≤.
  Must be easy to install and use the same input sequences on all platforms.
    https://docs.perl6.org/language/unicode_entry
    https://github.com/kragen/xcompose/ (for Unixy systems)
    https://github.com/SamHocevar/wincompose (xcompose for Windows)
    https://github.com/tekezo/Karabiner-Elements (macos, but not xcompose)
  Or, represent Curv source as ASCII, and use solutions like a programmer's
  ligature font or a custom IDE to improve readability of source code.
* Use _ as digit separator in numerals.
* 'foo' quoted identifiers. Compatibility with GUI interfaces that display
  parameter names as GUI labels.

## Parametric records
For example, a parametric shape in file `lollipop.curv`:
  param
    diam = 1;
    len = 4;
  in
    union(candy, stick)
  where
    candy = sphere diam >> colour red;
    stick = cylinder {h: len, d: diam/8} >> move(0,0,-len/2);
This returns a record (union(candy,stick)) augmented with a `call` field,
a function with parameter {diam=1,len=4} that returns a customized
version of the record.

The command
  curv -Dlen=6 lollipop.curv
modifies one of the shape parameters. Actually it treats the result
value V as a function, and calls V{len:6}.

This design does not put the parameters into the record. They might conflict
with field names in the (extended) shape protocol. It might make sense to
add a single field which is a parameter record. What to name it?
Not `param`, that's a reserved word. Maybe `p`.

## OpenSCAD2 prototype oriented programming?
* Model parameters and shape are bundled into one value.
* Simple syntax for customizing a subset of model parameters, generating
  a new shape.
* The BOM feature: can extract model parameters from a model script,
  generate JSON output.
* Language support for using a GUI to tweak model parameters?
  `param bindings in shape`. But what does this construct? Are the parameters
  represented in the value that is constructed, or does the GUI interpret
  the syntax?
* CSG trees: output a CSG tree as JSON, read a CSG tree to reconstruct model.
  Shapes contain the name of their constructor, and their constructor
  arguments. (Implemented using a proposed 'constructor' feature.)

## Data Abstraction:
* Wm. Cook distinguishes two kinds of data abstraction: CLU style "ADT"s,
  and Smalltalk style "objects". The untyped lambda calculus is enough to
  do object oriented data abstraction. Record literals make it easier.
  http://www.cs.utexas.edu/~wcook/Drafts/2009/essay.pdf
* I don't need extra features to support CLU-style information hiding.
  It's not that important.
* I do need the ability to define shape "subclasses" that obey specialized
  protocols. Eg, symmetrical polyhedra that support the Conway operators.
  I can already do this: a shape protocol is defined informally as a set of
  shape fields and axioms. I don't need explicit classes or inheritance
  or other explicit language mechanisms.
* This approach uses "duck typing". A shape just has to obey the protocol,
  it doesn't have to explicitly declare that it obeys the protocol.
* Do I need a language mechanism that allows a shape or record to declare what
  protocols it supports, in support of a cheap protocol testing predicate?
  (Like `val isa protocol`.)
  * I like the idea. I want it for type declarations, Design By Contract, etc.
    And for overloading positional arguments based on type, rather than relying
    on parameter labels as in Smalltalk & Swift.
  * But it's complicated to design, implement, document.
  * Cook observes that Smalltalk programmers generally don't need or use such
    a feature. So it's likely I don't need this in Curv.
  * Cook observes a tradeoff between flexibility (duck typing) and type
    correctness (explicit typing). Academics prefer type correctness.
    Some dynamic language communities (eg Smalltalk) prefer flexibility.
* Thus: In 1.0, support labelled parameters, de-emphasize explicit typing
  and type predicates.
* By this logic, I can get rid of the built-in Shape type.
  There are now 7 types: the 6 JSON types, plus functions.
  A shape is a record that implements `is_2d`,`is_3d`,`dist`,`bbox`,`colour`.
  This is the "shape protocol". `make_shape` is implemented in Curv, defines
  missing fields using default values, aborts if a bad field is detected.
* Do I need "inheritance"? Ability to override data or function fields
  while maintaining self-reference in function fields. That's needed for OOP.
  Right now, I'll say no.

  Note if you build an object-like data abstraction using records, with
  fields representing instance variables, and fields representing methods
  that reference the instance variables (function closures that contain
  separate copies of said instance variables), then reassigning an instance
  variable will leave the methods out of sync with the instance variables.

  So use a programming idiom that avoids this. To update an instance variable,
  you actually transform a value into another related value, using a function
  that invokes the constructor with a transformed copy of the instance variables
  as arguments.

## Function/Record Equivalence.
* Using {call x = f x}, a record can behave like a function.
* For symmetry, a function behaves like a record with a single `call` field.
* What about `is_fun`?
  * Get rid of `is_fun`. `is_record` is true for primitive functions.
    Test for `call` field in a record to identify a function.
  * Or, `is_fun` is true for records that contain a `call` field,
    and `is_record` is true for primitive functions. So Fun is a subtype of
    Record.
    * Then, what about lists and strings, which also support function call
      syntax? Are List and String subtypes of Fun? If so, then `count` cannot
      be polymorphic across Record and List. We maybe need to use
      `count(fields record)` to count the fields in a record.

## Haskell algebraic type constructors
  data Maybe a = Nothing | Just a
Constructors for this type, in Curv:
  {Nothing:}     -- or `null`, to be idiomatic.
  {Just: 42}
New feature:
  The expression {foo:} is an abbreviation for {foo: true}.
  The pattern {foo:} matches the record {foo:true}, binds no parameters.
  Can't specify a default value for a field pattern like `foo:`.
Eg,
  align{x:{centre:}, z:{above:0}}
Eg,
  make_shape{is_3d:, ...}

In the Symbol/Variants proposal, I would use
  align{x: #centre, z: {above:0}}
  #null and {just: 42}

## Prefix Sections
This is inspired by 'sections' from Haskell.
In certain cases, an infix operator may be used as a prefix operator,
which causes it to be partially applied.

 1. Backtick operators.
    (`foo` b) a <=> (a `foo` b) <=> foo(a,b)
 2. Relational operators.
    (== b) a <=> a == b

For example, a more uniform syntax for shape pipelines:
  gyroid
    >> shell .2
    >> lipshitz 2
    >> bend (tau*12)
    >> `smooth .1 .intersection` torus(tau*4, tau*2)
    >> colour (sRGB.HSV (1/3, 1, .5))

And,
  map (`sum` 1) list
  filter (>= 0) list
  filter (`equal` 0) list  // see Vectorized boolean operators

There are also section patterns, when the section happens to be a predicate.
  match [(== 0) -> ...] -- section pattern
  match [(`equal` 0) -> ...] -- section pattern
Actually, this is really only useful for `==`, which is good for simulating
a `switch` statement. Otherwise you probably want to capture the argument value
in a parameter, eg `(x < 0) -> ...`. And then you could write `(_ == 0) -> ...`
as a case in a simulated switch.

This can't be extended to the arithmetic operators, since (+a) and (-a) already
have a different meaning. Sections of the boolean ops && and || aren't useful.

August 2019: 'into f [x]' is equivalent to the proposed (`f` x).
`into` is my new solution to providing a more uniform syntax for shape
pipelines.

## Action/Generator Abstraction
Support tail recursion as a form of iteration in list/record generators.
This could mean:
* New syntax: a recursive loop construct whose body can be an action or
  generator. Previously designed as `loop` (aka Scheme named let).
* Lambda abstraction for actions, list/record generators.

## Function Composition
Long-form function composition is `compose[f,g]`.
Maybe I want an abbreviated infix form?
    f'g
This looks nice if each function in the composition is an identifier.
The syntax makes sense if I create a library of standard function names
that are intended to be composed in this way.

Compose a colour map with an intensity field.
There are a bunch of standard named colour maps and intensity fields.
eg, rainbow'linear_gradient
    rainbow'radial_gradient
    greyscale'cosine_gradient

Transformations can be composed.

co[f,g] or f `co` g

## Add shebang comments, `#!` to end of line

## Add code comments, `(*` token_or_comment* `*)`
Nestable comments for reliably commenting out code blocks.
* In Rust, `//...` are the recommended style of comments for most purposes.
  `/*...*/` are nestable, and are for commenting out blocks of code.
  So, use `/*` instead of `(*`. Don't have 3 comment syntaxes.
* Or, simplify, and get rid of `/*...*/`. Use comment/uncomment commands in
  a programmer's text editor to comment out blocks of code.
* Extend Gedit so that it can comment/uncomment code blocks in Curv using `//`.

## Eval
eval string        -- use std environment
eval(string,env)   -- environment is env, then std

I'm not saying this is a good idea, BTW. It just keeps coming up, so it
needs a section. Eval is easy to implement, but there are probably better
APIs for anything you might actually use it for.

Use cases? Ummm... convert a string to a number? Using Curv as a general
data transformation language, outside of making shapes? See also: Jq.

If I actually want to manipulate Curv programs as data (which is outside any
use case I'm considering) then strings may not be the best representation.

## get and update
Traverse and update a data structure (nested records and lists)
using path values. A path is a list of list indexes and record field names.

Curried, pipelineable API:
  get path structure
  update (path, newvalue) structure

Update uses the unique reference count optimization, available once we have
an optimizing compiler and a new instruction format that supports it.
* `amend` is an alternate name for `update`. Shorter, more precise.

## Multipart Definitions
Multipart function definitions:
    f (x :: is_num) = ...;
    f (x, y) = ...;
    f (x, y, z) = ...;
is similar to
    f = match [
        (x :: is_num) -> ...;
        (x, y) -> ...;
        (x, y, z) -> ...;
    ];
except that the former can be recursive (one case can be defined in terms of
another case).

Multipart record definitions:
    r.a = ...;
    r.b = ...;
    r.c = ...;
is the same as
    r = {
        a = ...;
        b = ...;
        c = ...;
    };
