A procedure is a lambda-abstraction of a statement.

Benefits:
* Make it possible to replace any use of `for` with tail recursion.
* Make it possible to use `match` in any context where `if` is legal.
  Eg, in a list comprehension.
* Once I have an interactive debugger, and a rich set of actions for
  controlling the debugger, then procedures are used as debugger scripts.
* print, error, warning, assert become values.
* Another step in making it easier to port imperative code?

Brainstorming results (so far):
* An action value is an unevaluated generator or debug action.
* `!<action>` is a generator/statement that invokes an action.
* A mutator function abstracts a statement wrt mutable variables.
  Now called a 'procedure': see [[next/Proc]].
* Switch statement.

See [[abstraction/Generators]] for a somewhat opposing earlier view,
where I claim that generators and statements are distinct.
More lately, after writing this essay, and seeing the complexity of the
full proposal, I've returned to the idea that generators and statements
should be distinct. See [[next/Actions]].

Proposal #1: Generic Phrase Abstraction
---------------------------------------
A simple approach is to declare that functions, ie
    pattern -> phrase
are generic across expressions, generators and statements, just as
the 'if' and 'let' operators are generic across these phrase types.
Tennent's "principle of equivalence" is fulfilled (let/function equivalence).
These values are generically called 'functions', and is_func is true.

So now print, warning, error, etc, are first class function values,
without any syntax change. The weirdness in the 'error' implementation
is removed. 'exec' is now obsolete.

For a statement function that doesn't need parameters, we use the convention
that the argument is []. Which corresponds to () in Haskell, the Unit type.
No such convention is needed by the 'proc' proposal. But this convention will
be familiar from most mainstream languages, so it won't impede learning.

Function call is overloaded: a funcall is an expression, generator or statement.
Call_Expr is replaced by Call_Op which has ::eval and ::exec.
No need for the '!proc' syntax from the 'proc' proposal. Again, funcall syntax
for a procedure call will be familiar from mainstream languages.

Mutator functions have a statement or generator as a body.
    mf x
is a function call where the argument value 'x' is bound to a mutable
local variable in the body of 'mf', which is executed in action context.
    loc!mf
is a statement that mutates the 'loc' argument and may also generate values.

It is possible to write combinators that are generic across phrase types,
where the 'phrase type' of a function call can depend on the argument.
I'm not sure how useful this is, although 'match' is an example.

Concerning imperative combinators, such as a 'while' function:
Curv isn't a GP imperative language -- closures do not capture references
to mutable variables. Mutator functions provide a 'functional' way to
accomplish the same things. Maybe like
    local total = 0;
    local i = 1;
    [i,total]!mywhile ([i,_]=>i < 10) ([i,total]=>(total+:=i; i+:=1))

Critique of Proposal #1
-----------------------
It bothers me (at a gut level) that a function call phrase like 'f x'
is either an expression or statement, but I can't tell by looking.
It feels like ad-hoc overloading.

It also bothers me to put a print statement like [..., print "foo", ...]
into a list expression, possibly for the same reason. Maybe I prefer
    [..., !print "foo", ...]

The problem is that in every other hybrid functional/imperative language,
starting with Lisp and Algol 68, and in the ML family, a procedure is
represented by a function with side effects that returns the Unit value.
So [..., print "foo", ...] would add the Unit value as a list element.
In every other language, the function call syntax returns a value, which is
ignored in imperative context. Proposal #1 creates cognitive dissonance.

Is there a solid mathematical basis for this preference?
Do I get better algebraic properties if function calls are always expressions?
Maybe I should create a denotational semantics for Curv.

Function call overloading breaks algebraic laws.
`compose[f,g,h]`: f & g must be expression functions, h may be a
non-expression function, but if it is, then id is not a right identity.
The `proc` proposal avoids this by distinguishing procs from functions.

If 'f x' is not guaranteed to be an expression, then my plan to produce
more precise blame in error messages by examining the syntax of a function
call argument breaks down when I encounter a function call expression as
an item in a list constructor argument. (There would still be a breakdown for
a procedure call in a list ctor, generating an unknown # of values.)

Classifying all function varieties as 'is_func', without a specific subtype
for expression functions, limits checking of function arguments.

Since debugger interaction is not classified as a side effect, expression
functions are a subtype of general functions. The former return a value,
the latter can generate zero or more values. The kind of function that
returns 0 values may also want classification, since that's the only kind
you can call from a 'do' clause. So 'is_gfunc' is the general case of a
generator function, 'is_func' is an expression function, and 'is_proc' is
a gfunc that produces zero values.

In order to define 'is_gfunc', 'is_func' and 'is_proc', we need to be able
to deduce these types from a lambda expression. We need:
 * different syntax for gfunc, func and procedure call, and do type inference
   on the lambda body, or
 * different syntax for gfunc, func and procedure literals.

Proposal #2: Action Values
-----------------------------
This is a delta from prop #1 that fixes the cognitive dissonance problem.
The body of a function is an expression.
I'm ignoring the distinction between generator and statement abstractions.

An action value is:
    action <generator>
    action <statement>
Functions and procedures are orthogonal. You can use 'x->action <stmt>'
to abstract over subexpression 'x' in a statement. To call an action, use:
    !<action>
Note that `!` is kind of a replacement for `exec`, but not really, since
it is a generator. See below.
'print', 'warning' etc become functions that return actions. So you write:
    !print "hello world"
Predicate: `is_action`.

An action cannot capture a reference to a nonlocal mutable variable, so actions
are not a true abstraction over imperative statements. However, they are a true
abstraction over generators and debug effects. They are semantically equivalent
to the generator values of [[abstraction/Generators]].

Semantically, an action is like a mutator function
that mutates an Executor argument (eg, adding items to a list or record).

Distinguishing Generator abstractions from Debug Action abstractions
--------------------------------------------------------------------
At various times I have wanted this design to support a clean distinction
between an unevaluated generator vs an unevaluated debug action, with
different value types and different invocation syntaxes.

I think that I have pretty much accomplished this with proposal #2.
* An unevaluated generator is an action value. The syntax
    !<action>
  generates 0 or more values (and can also have debug side effects, but that
  is also true for functions).
* An unevaluated debug action is a mutator function with [] as its parameter.
  The syntax
    []!<debug function>
  invokes it, causing debug effects, but not generating any values.
  I do not have a predicate for this (functions whose domain is the single
  value []).

Logically, if I want to partition reality in this way, then the syntax
for a print statement should be
    []!print "hello world"
Bletch.

Another idea is to provide two syntaxes for invoking an action:
    !<action>   -- guaranteed not to generate any values
    ...<action> -- generates 0 or more values

A possible benefit of making 'debug action' a subtype of 'generator'
is polymorphism. You can use 'print "hello"' as an empty generator,
in any context requiring a generator argument.

What kind of generic code benefits from representing a debug action
as a unit function (from [] to [])? You can compose them with `compose`.

Proposal:
* A generator value is a linear function from List_Builder to List_Builder.
  Record_Builder is a subtype of List_Builder.
* A debug action is an identity function with side effects. This makes them
  maximally generic: they can be inserted into any sequential execution
  sequence.
  * Debug actions can be composed using `compose`.
  * Can be composed between two functions: `compose[f,print "foo",g]`
  * A debug action is compatible with a generator value.
  * A debug action is compatible with any mutator function, and can be
    inserted into any chain of mutator functions:
      x!reverse!print "hello"!to_lower
* The syntax `!<lfun>` invokes a linear function to transform the "current
  state" in an imperative context, which could be '[]' (in the head of a
  begin expression), or could be a list or record builder, or could be something
  else in the future. In the "programmable semicolon" future of Curv, an
  action is a linear function that transforms the current state of a statement
  list. Debug actions and generators are two special cases of actions.

Switch Statement
----------------
None of these allows `match` to provide nice syntax for a switch statement,
in the case where the switch arms mutate local variables. You need to write
    a!x>>match [
        1 -> a=>a:=1;
        2 -> a=>a:=2;
        ...
    ]
which is boilerplatey in its need to repeat the list of variables being
modified in each arm of the conditional.

Shader language has a switch so I suppose that SubCurv needs a switch.

Generators are not Statements?
------------------------------
A generator is a generalized expression, part of the declarative language.
A statement is part of the imperative language. We should have different
constructs for an unevaluated generator and an unevaluated statement.
The latter is a procedure. The former is something else, maybe a lazy list?

But: There are also generator statements. And I want 'mutating generators'
so that I can use a state machine to drive a generator. To invoke an MG, use
    yield loc!mg
which mutates a locative and also inserts values into the generator output.
I don't like 'loc!mg' by itself because there's no syntactic indication that
values are generated.

Kinds of Procedures (Dec 2020)
==============================
Here are two viable kinds of procedures:

 1. Procedure
    This is a statement, reified as a value. When executed, it can have
    debug effects, and that's it. Recursive procedures are supported.
    There's not much utility here without a richer set of debug actions.

    Possible constructor syntax:
        proc <statement>
    In offside syntax,
        p x = proc:
            stmt1
            stmt2

    Possible call syntax: <statement> ::= !<proc>

    Most of the builtin metafunctions can be replaced by procedure values.
    !print x; !warning x; !assert x

 2. Mutate Function, aka Mutator,
    aka Ref Function (call-by-reference function)

    This is a statement abstracted over mutable variables, but externally
    it behaves like an ordinary function. The benefit is using 'linear
    logic' and imperative code to efficiently mutate a data structure.
    You invoke it by passing a locative to mutate.
    The effect is to mutate the locative. There are no generator effects,
    those would be side effects. Mutators are supported by SubCurv:
    in GLSL, function parameters can have the 'inout' attribute.

    Possible contructor syntax:
        mutate <locpattern> in <statement>
        ref <locpattern> -> <statement>
    (For offside syntax, we prefer a keyword preceding the statement.)

    Possible call syntax: <statement> ::= <locative>!<mutator>
    * A mutator can be called like an ordinary function, mapping a value
      argument onto a value result. Internally, the value is bound to the
      locative formal parameters, the statement body is executed, the contents
      of the formal parameters are reconstituted into the result value.
    * A function can be invoked as x!f, same as x := f x
      This syntax is chainable, and is evocative of a chain of mutator
      methods in Object Oriented Programming.

    x!negate; x!reverse
    x!reverse!negate

    In imperative languages, it is idiomatic to create two versions of each
    function that can be efficiently implemented by mutating its argument:
    a functional version, and a mutating version.
    * In Scheme, '(reverse x)' vs '(reverse! x)'.
    * In Python, 'reversed(x)' vs 'x.reverse()'.
    In Curv, there is only one 'reverse' function, and the syntax shows
    unambiguously whether mutation is occurring or not.
        x >> reverse
        x!reverse

This does not provide full abstraction over the statement language.
It separately provides abstraction over assignment statements and generators,
filling in the two biggest holes.

Challenge: Mutable Variables
----------------------------
I just redesigned Curv so that mutable variables, the assignment statement,
and the while statement are fully supported and general within the imperative
sublanguage.

Those 'benefits' seem to require that procedures will capture references to
mutable variables. Which would violate the pure functional semantics of Curv,
if these procedures are first class values. It introduces shared mutable state.
This isn't going to happen.

The use cases for the imperative sublanguage are:
* Imperative algorithms using mutable variables & while statements.
  * To use pattern matching conditional statements in this code, we can't
    use the `match` function, we need a pattern-matching switch statement.
  * To use tail recursion, you have to convert the code to a functional form
    that uses pure functions instead of mutable variables.
* List comprehensions.
* Debugging and unit testing.

The latter two use cases could benefit from a restricted kind of procedure
that can't capture non-local mutable variable references. Further analysis
would probably reveal an underlying monadic structure to specialized domains
such as list comprehensions and debugger control.

The question is: are these use cases enough to justify procedures?
Maybe new monadic structures will arise in the future that will create more
of a need for this feature?

Challenge: Expressions vs Statements
------------------------------------
Originally, every Operation is either an expression or statement, determined
by syntax, meaning it can be determined at compile time.

A function/procedure call can be ambiguous: it can be either an expression or a
statement, depending on argument values. An if-else phrase can be either an
expression or a statement, ditto a call to error, so user-defined functions/
procedures can have the same property.

If we embrace this flexibility, then higher order functions
can act as either functions or procedures, depending on argument values.
Function calls can't be classified as expressions/statements until runtime.
Does this cause technical problems?
* No problem for the REPL.
* Future IR/executable format: no problem. Operations will be compiled into
  either expression or statement nodes (corresponding to Operation::eval()
  and Operation::exec()), based on syntactic context.
* But with segregated function/procedure call, we can do more analysis.
  We can distinguish expressions from value generators in a list constructor.
  Because we know that 'f x' is an expression, not a procedure call:
  * The partial evaluator can replace '(f x, a)[1]' with 'a'.
  * We can produce better At_Index error messages. Instead of:
        ERROR: at index [1]: true is not a number
        1|       [f x,true,3]
                 ^^^^^^^^^^^^
    we can say:
        ERROR: true is not a number
        1|       [f x,true,3]
                      ^^^^
  These benefits could be mostly restored with better compile time analysis:
  most functions could be classified as true functions at compile time just
  by looking at the syntax tree.

Does this flexibility cause usability problems?
Benefits are:
* More expressive power. 'error' is a value.
* Only one syntax for functions and for function call. Splitting these syntaxes
  introduces unfamiliar concepts not found in other languages.

Philosophical Challenge: Two ways to do it.
-------------------------------------------
Under this proposal, there are two ways for a function to return a sequence
of values: either by returning a single list value, like this:
    iota n = 1..n;
or by generating a sequence of values, like this:
    gen_iota n = ...(1..n); /* or */
    gen_iota n = for (i in 1..n) i;

During the pre-Curv design process (OpenSCAD2), I explicitly did not want to
support two ways for a function to return a sequence. I didn't want to
encourage fragmentation of library APIs, where you have to know which of the
two protocols was being used, and then possibly write glue to convert between
the two protocols, either '...iota n' or '[gen_iota n]'.

So now I have generators, which are phrases that generate a sequence of values.
Consider generators in Icon, or generators in Python.
I'd rather have lazy lists (like Haskell) instead.

There is no way to directly iterate over a generator. You have to
capture the output in a list or record first. Does this mitigate the problem,
by deterring the use of generator procedures in libraries?

"If you only have a hammer, then every problem looks like a nail."
Value generators will have a performance advantage over lists, in the
case where you are incrementally accumulating a list of values, eg 1 per
function call, due to the O(N) cost of list concatenation.

The Jq proposal, to extend Curv to embrace the features of Jq, actually
requires the use of value generator procedures (as a supertype of functions).
Haskell style lazy lists do not have the required semantic properties.
We need the concept of a flat stream of values, where embedding one stream in
another results in automatic flattening, and not a tree structure.

Proposal: Procedure Call Syntax
-------------------------------
Maybe the syntaxes for procedure and function call should be segregated.

Benefits:
* It can be helpful for human readability. It makes the procedural subset of
  Curv stand out syntactically from functional code.
* The compiler can distinguish expressions from statements at compile time.
  We can distinguish expressions from value generators in a list constructor.
  Because we know that 'f x' is an expression, not a procedure call:
  * The partial evaluator can replace '(f x, a)[1]' with 'a'.
  * We can produce better At_Index error messages. Instead of:
        ERROR: at index [1]: true is not a number
        1|       [f x,true,3]
                 ^^^^^^^^^^^^
    we can say:
        ERROR: true is not a number
        1|       [f x,true,3]
                      ^^^^
* After calling Program::compile(), you can query the Program to determine
  if you have compiled an expression, statement or definition, and then call
  Value eval(), exec(Consumer&) or Shared<Record> define()
  to execute each type of program.
  * Right now, the REPL doesn't distinguish between 'cube' and '...[cube]',
    because it can't distinguish an expression from a statement. No big deal,
    but now it can make that distinction.
* The proposal for compiling Curv into CPS instructions benefits if we can
  generate different code for expressions and statements.

A proposed syntax for procedure call:
  postfix ::= postfix '!'   -- this is a procedure reference, not an expression
  procedure call syntaxes:
    procedure_ref primary
    expression >> procedure_ref
    procedure_ref << expression
For example,
  print! "hello world"
  "hello world" >> print!
Curried procedure call is a bit odd:
  myproc a b! c

If you call a procedure using function call syntax, or call a function using
procedure call syntax, you get an error. So procedure and function values must
be internally distinguished in some way.
* Maybe not. This seemingly conflicts with the doctrine that Expression
  is a subtype of Value_Generator. So is Function a subtype of Procedure?
* In the discussion of `jq`, it's useful to consider Function to be a subtype
  of Value Generator Procedure.
* So this would mean, calling a function with procedure call syntax results
  in a value generator phrase. Which might cause an error if the context
  doesn't allow this. But it would be legal in a list constructor.

* `print`, `warning`, `assert` are procedure values.
* As a special case, `error` is both a procedure and a function.

Two type predicates: `is_fun` and `is_proc`.

Libcurv has a "generalized function" class with both a call() method
(for function call) and an exec() method (for procedure call).

Lambda expressions and functor definitions need not have segregated syntax
for procedures and functions. The compiler doesn't need it, it would only be
for the benefit of human readers, if there is a benefit. Syntax could be:
    param => statement
    param1 -> param2 -> finalparam => statement
    identifier! param = statement;
    identifier param1 param2! finalparam = statement;
If a procedure body is an expression, it's treated as a value generator.
Without this syntax, you would use `x->...[x]` for a procedure that generates x.
With this syntax, you could use `x=>x`.

Can a Curv source file contain a statement?
We could use `file! filename` to execute such a program.

A procedure cannot reassign a nonlocal sequential variable
----------------------------------------------------------
`x := x + 1` cannot be the body of a procedure, because of restrictions
on the scope of sequential variables.
* The OpenSCAD 'do' proposal had procedures with by-reference 'var' parameters.
  If 'x' was a 'var' parameter then this would be legal.
  However, this idea doesn't allow us to simply evaluate procedure argument
  expressions to pure values.
* Not a problem. The important use case is action procedures.
  In that case, you write a function that invokes actions as side effects,
  using `do`, and you just return the results from the function call.

Proposal: Unified Function and Procedure Values
-----------------------------------------------
* No new syntax.
* print, warning, assert become values with no syntax change.
* error is a value, only one syntax to invoke it.

When a function is called, it optionally causes side effects, it optionally
returns a value, and it optionally generates a sequence of elements or fields.
The context of a function call determines which of these behaviours are legal.

Since we distinguish returning a value from generating a single value,
and since there is no `!` marker to distinguish procedure from function calls,
I want the REPL to distinguish generated from returned values in the output
of a command. A `>` prefix for generated values.

Instead of Program::eval() and ::exec(), we have ::run().

Proposal: Procedures are not Values
-----------------------------------

Old Thoughts about Procedures
=============================
Procedures (Functions returning actions or generators):
* A statement is an action, value generator, or field generator.
  A procedure is a function that abstracts over a statement.
  Procedures are values, but can only be invoked in a statement context.
* Pragmatic justification:
  * It should be possible to replace any use of `for` with tail recursion.
    This requires procedures.
  * It should be possible to use `match` in any context where `if` is legal.
    Eg, in a list comprehension. This requires procedures.
  * Once I have an interactive debugger, and a rich set of actions for
    controlling the debugger, then procedures are used as debugger scripts.
  * print, error, warning, assert become values.
  * Maybe I get rid of metafunctions, and all of the metafunction bindings
    in the standard prelude become values or keywords. Now the standard
    prelude can be represented as a record value.
* Theoretical justification:
  * You can abstract a statement with a let block.
    According to the principle of equivalence, this means you should also be
    able to abstract these phrases using functions.
  * Suppose I use the Haskell 'monad' trick to implement phrase abstraction.
    Then a statement is a function value (with a weird argument type, of a
    special type of value that can't be counterfeited, like the IO type in
    Haskell). A procedure would then also be a value. This
    demonstrates that procedures can be made theoretically sound.
* Challenges:
  * Can I invoke an arbitrary procedure from the command line?
  * `...` is ambiguous in a weak context. So I can't mark a procedure as being
    an action, element gen or field gen abstraction at value construction time:
    it could be argument dependent, as in `spread x = ... x`.
    So procedure calls are ambiguous in a weak context.
    Does it help if I split `...` into 2 operators?
  * `seq(p1,p2) = (p1();p2())`. Another polymorphic procedure. Since `if`, `for`
    and `;` are polymorphic operations on statements, this naturally leads to
    user defined polymorphic procedures.
  * By creating a set of higher order procedures (combinators), you could write
    procedures whose bodies look like expressions: no syntactic clue that they
    are procedures. A function can be polymorphic across the expression and
    statement worlds. The Haskell Monad argument justifies this as meaningful.
  * Right now, [f(x)] compiles into code that evaluates f(x) as an expression.
    A user can tell by inspection that this is a 1-element list. But no more.
    We need to compile into less efficient code (in the general case), and do
    more work to identify the efficient case.

What is `x := x + 1`? Can this be the body of a function?
* Ugh. Sometimes the drive towards full expressive power creates monsters.
  Eg, `call/cc`: generalized goto labels as first class values. Leads to code
  that is nigh impossible to understand.
* Don't be misled. From a monad perspective, `x:=x+1` is a pure function that
  transforms a state value to a state value. This state value is some
  abstraction of the scope that variable `x` is defined in.
  * The state value could be a totally locked down, non-counterfeitable
    abstraction of the frame containing the slot for `x`.
    Maybe each frame has a signature, and `x:=x+1` checks that its state
    value is a frame with the correct signature.
  * The state value could be a record containing the field `x`.
    And there's a bunch of research needed to flesh this out and make it
    efficiently compilable.
* The OpenSCAD `do` proposal had procedures with reference (var) parameters.
  This is more actually useful than the ability to mutate non-local variables.
* Maybe mutable variables are deliberately limited and deprecated.
  Use functional style if you want unconstrained abstraction.
* A procedure cannot reassign a nonlocal sequential variable.
  Use a function instead: `(V1, V2) := F(V1,V2,0);`

I think this is technically achievable.
But it's a can of worms with limited utility.
Consider defining a subset of this that provides the greatest benefit,
to limit the implementation and design cost.
Not for MVP.
