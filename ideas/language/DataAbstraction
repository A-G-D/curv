Data Abstraction
================

Tar Pit or Virtue?
------------------
The modern practice of OOP leads to code with thousands of classes, an
explosion of specialized ADTs, bloated code that is mostly boilerplate,
and a huge tower of abstraction, code built on top of deeply nested giant
libraries that nobody understands. Data abstraction mechanisms in OOP languages
are incredibly complex and account for most of the language complexity.

Haskell isn't OOP, but it is 'typeful programming', where the coding task is
dominated by defining and using large numbers of ADTs. There's a high learning
curve due to the complexity of the type system and the libraries.

The opposite of this is the practice of programming in APL/J/K, where there
are no data abstraction mechanisms, and you encode most data as nested arrays
of numbers. You make little or no use of libraries; you just apply the very
powerful language primitives to your arrays of numbers to get things done.
Curiously, this leads to much shorter code, and much lower overall program
complexity due to the absence of dependencies. Eg, look at the co-dfns project:
an optimizing APL compiler in 750 lines with no dependencies. Down side: the
code is opaque.

Clojure is a less extreme reaction against the excesses of OOP. Being a
pragmatic language that integrates with the JVM, it doesn't entirely eliminate
data abstraction, and Rich Hickey admits that ADTs still have a small role to
play. Clojure tries to remove much of the complexity of OOP. There are still
classes, but no information hiding, and no implementation inheritance. Instead,
genericity is obtained by implementing interfaces/protocols. There are still
nominal types, but most data should be stored in generic collections and maps.

Curv needs to find a middle ground between the no-abstraction Turing tar pit
and the typeful programming/OOP tar pit. If "no-abstraction" is taken to its
logical conclusion, you get shadertoy.com, where you code in raw GLSL and
there are no reusable libraries. This coding style is just too difficult.
We need higher level abstractions, including data abstractions. We need
libraries of reusable code. We need the ability to define DSLs within Curv
to simplify the use of various artistic techniques, eg like L-systems.
But the language needs to be kept very simple.

What Curv Needs
---------------
Curv has informal data types like Shape, Colour, Intensity Field, etc.
There already is data abstraction; the question is what language support do I
need? The language must be kept simple, so what are the minimum requirements?

The data model should be simple: when you print a datum, what you see
is all there is. However, Out Of The Tar Pit advocates a separation between
"essential" and "accidental" data, to reduce complexity. In a Shape value,
the 'essential' data is really the constructor and constructor arguments,
while the 'accidental' data are all the fields generated from the constructor
arguments. Printing a shape with all of its fields is already a confusing mess,
which is why I have a kludge to suppress that information.

There will be no OOP classes: no information hiding, and no implementation
inheritance.

I might want a concept of tagged values. Provisional syntax:
    #tag:primary_expr
The payload can be any (untagged?) value. A tagged value behaves just like
its payload when passed to most primitive operations. Possible use case:
use #colour:[r,g,b] to tag a colour value, so that colours are graphical values,
and so that a colour picker is invoked to edit the value in the visual editor.

Data Abstraction and Generic Programming
----------------------------------------
Data Abstraction means several things to me:
* The act of coding a generic algorithm, which involves specifying the
  minimum requirements on the data that the algorithm acts on.
  I would like to support generic programming in Curv, as long as it doesn't
  involve too much language complexity. Ideally, generic programming arises
  as a side effect of simplicity, orthogonality and generality, rather than
  being supported by complex, specialized features.
* The complex facilities found in general purpose languages for defining
  data types, which may include classes, inheritance, information hiding,
  types, user defined types, type constructors, and so on. These features
  in C++, Haskell, CLOS, etc, are far too complex for Curv.

The original Curv design rejects complex features for defining data types.
There are only 7 types: the 6 JSON data types, plus functions. There are no
user defined types, and no concept of a named type. You represent data
structures the same way you do when encoding them in JSON.

I'm not 100% happy with this.
* In some cases, like shapes, the representation can be large and messy,
  and I don't always want to dump this representation on the screen
  when you examine the value.
* There are some technical benefits to storing the CSG tree in a shape value.
  Eg, for symbolic export of a shape, to an SVG file.
* Parametric shapes know what their parameters are, and let you interactively
  modify those parameters using a GUI.
So now I want to separate the outside representation of a shape from its inside
representation (both can be examined). The outside representation is a
constructor name, and a set of parameters.

So there is plain and branded data.
* Plain data is JSON data, and you construct it directly using using JSON
  value constructors. When you print the data, it looks like JSON.
  Pattern matching works using JSON value constructors.
* Branded data is constructed using high level constructor functions.
  The underlying representation is usually a record.
  When you print the data, it looks like calls to high level constructor
  functions. Pattern matching uses calls to constructor functions.
  So this is a kind of data abstraction.

[Functions are maybe another kind of value where you have an outside and
an inside representation. In some languages that are based on Symbolic
Expressions, a function is represented internally by a data structure that
you can examine. I can see some utility in doing this for Curv: it provides
a low level mechanism that would allow more language primitives to be coded
in Curv rather than in C++. But this is tangential to the main concerns of
this page.]

Branded Data
------------
* Branded data is constructed using high level constructor functions.
* The printed representation looks like calls to constructor functions.
* Pattern matching uses calls to constructor functions.

Equality compares the constructor name and the argument values.
This is the only way to get meaningful equality tests for shapes, or any
other compound data that includes functions.

Branded data is important for visual programming. A parametric shape is a
branded datum with constructor arguments that you can tweak in the Viewer
window using graphical value pickers. Branded data may be nodes in a node-based
visual programming environment.

Branded data can support a particular style of generic programming, where
CLOS-like generic functions have different implementations for different
constructors. Like Haskell type classes, except with dynamic dispatch.

Branded data will use the simplest design that meets the requirements:
* A shape (may) contain its CSG tree in symbolic form.
* A parametric shape contains its parameters and its constructor function.

There are many possible designs.

OOP:
    Branded data are records. Parameter names and shape fields occupy the same
    namespace (both are just fields). Class names and inheritance. There is a
    shape class, and every concrete shape inherits from that.
Records have branding metadata:

Maximally Generic Functions
---------------------------
I'll start by describing a system that maximizes the reuseability and
generality of generic functions.

A Signature is:
* A set of abstract type names.
* A set of value and function names, together with requirements that
  give the semantics of these value names.
  A requirement for a value name could be a type signature, written in
  some static type language. For a simple example, value V has type T,
  where T is one of the abstract type names.
  Requirements can more generally be axioms: equations
  that must be true, involving one or more named values.
  Since axioms can describe relationships between two or more named values,
  they can describe requirements that can't be described using just a type
  signature.

Signatures can be organized into a multiple inheritance DAG.
Examples from abstract algebra: Group and Monoid are signatures;
Group is a subsignature of Monoid.

A Structure is an instance or a concrete implementation of a Signature.

Note that Structures are not contained inside of types, so this is not like
OOP. You could have multiple structures, defined in different modules or
packages by different authors, that implement different signatures for the
same concrete type. For example, you could have two different structures
that implement the Monoid signature for Number: one would be the additive
monoid, the other the multiplicative monoid.

An interface in OOP is like a restricted Signature over exactly one type.
And a class in OOP is like a Structure that implements an interface.

A generic algorithm is an algorithm that uses named types and values and
functions described by a signature. A generic algorithm can be instantiated
for any structure that implements that signature. When a structure contains
one or more functions that are defined in terms of the structure's signature,
those functions are generic algorithms.

My model for this system is the SML module system.
C++ templates are another system with this goal.
A related system is Racket's combination of Units and Mixins:
http://www.cs.utah.edu/plt/publications/icfp98-ff/icfp98-ff.pdf

What these systems have in common is that, in order for a generic
algorithm to be maximally generic, it must be embedded in some kind of
parameterized module. Eg, the parameters can have signature types and the
arguments can be structures. Maybe all of the parameters have default values,
but to cover all the use cases, you have to be able to explicitly invoke
the module multiple times with different arguments.

Curv can mostly do this already. You can define a generic function inside
a parameterized record, and invoke the parameterized record with structure
arguments. You could even use a parametric record, so that passing an
argument is completely optional.

There is missing syntactic sugar: if the structure defines a '+' operator,
you can't invoke it from inside the generic function using a+b syntax.
* What would that look like? Maybe, following Mathematica, a+b is a hardwired
  synonym for plus[a,b].
    S.plus(a, b)
    a S.+ b

In Mathematica, code and data are represented by symbolic expressions,
which can be manipulated as data. I think you can also reinterpret the meaning
of unbound symbols within an S-expression. In which case, there is no need
to plan ahead and explicitly parameterize a generic function with respect to
its dependencies?
* If this account is true, then it is in conflict with the idea of a closure,
  where a function value carries around bindings for all of its dependencies.
* Curv could have operations for querying and modifying the environment of a
  closure. Is this a good idea? It seems related to the idea of a parametric
  record, which also has an 'environment' that you can query and modify.
* I suspect that genericity may be more complex than this. Perhaps, in some
  cases, it is necessary to decide which occurrences of '+' belong to which
  signatures. Either your type system deduces this for you (as in Haskell with
  type classes) or you do it manually.

Dynamic Type Tags
-----------------
Curv is dynamically typed. Curv values contain type tags that attest to
their type. A type is not the same thing as a signature or a structure,
so this is different from OOP, where a class is a type. Signatures contain
abstract type names, and values contain type tags: am I using the word "type"
consistently in these two cases? Maybe a Signature is a Pattern.

What are the possible type tags?
* List values contain an element type. This is for efficiency reasons.
  A general list [a,b,c] can contain any type of value.
  A string "abc" is a list restricted to only contain character values.
  Once I support image import, I will have image data values, which are
  arrays of pixel values, using a compact type-specific representation
  for the pixel values (ie, not 64 bit boxed values). And I will have types
  that correspond to various pixel value representations.
  In-place update of a list will be restricted to members of the list's
  element type.
* Atomic types (null, bool, character, number) have a type tag.
  Looks like there will be multiple numeric types, due to image import.
* There are an infinite number of record type tags.
  There's some way to construct a branded record, I think.
  Maybe related to the 'term' proposal.
  Record branding means we are diverging from duck typing.
  But, it allows overloading an interface,
* Function values can also be branded. A brand on a function attests to that
  function having certain properties, so we are diverging from duck typing.

Is there a concept of "subtype" for type tags?
I think so. An imported 8 bit greyscale image has pixel values in the range 0
to 1, but represented as 8 bits, not as 64 bits. So that's a subtype of Number.
(Julia doesn't have subtype relationships between concrete types.
On the other hand, Julia has abstract types, which I don't think makes sense
in my framework. I have signatures and structures instead.)
