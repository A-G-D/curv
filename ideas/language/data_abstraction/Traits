Generic Programming
-------------------
A generic algorithm imposes a set of requirements on its arguments:
* Which operations must be supported by each argument? This can be determined
  by examining the source code of the algorithm.
* What laws and axioms must these operations obey?

Sets of requirements like this can be modelled as algebras. In the general
case we need multi-sorted algebras. In the C++ literature, these requirement
sets are called Concepts.

The requirements that an algorithm imposes on its arguments arise organically
from the act of writing the code, and developers are typically unaware of the
exact requirement set. In statically typed languages, developers are forced to
specify type constraints on arguments using a type language, and this normally
reduces the generality of algorithms. Type systems that don't artificially
restrict the generality of generic algorithms are a research problem.
In dynamically typed languages, you don't worry about this crap,
and algorithms don't have artificial type restrictions on their arguments.
The term 'duck typing' is often used to describe this.

Data Abstraction
----------------
What is the syntax for invoking the operations of an Algebra, for interfacing
our data with generic algorithms?

1. OOP style.
   value.opname arg

   Data and operation names are mixed in the same namespace.
   With classless OOP, data is complected with operations (operations are
   closures that capture the data): this prevents data structure update.
   With class OOP, another kind of complexity occurs: the operations
   access the data and each other via 'self' reference. Finally, this style
   privileges the first argument of an operation, which doesn't work well with
   binary operations in an Algebra (Magmas, etc), or with multi-sorted Algebras.

2. Functional style.
   opname arg value --or-- value >> opname arg

   The operations and the data are orthogonal to one another.
   Works with binary operations and multi-sorted algebras.

3. Namespaced functional style.
   M.opname arg value --or-- value >> M.opname arg

Overloading
-----------
How do we arrange for multiple different types, with different internal
representations, to support the same abstract interface? In general we need
different implementations of each operation for the different types.

1. Piecewise functions.
   An operation, that is part of an abstract interface, uses `match` to
   pattern match an argument, and executes different code for different cases.

   In order to support an existing interface on a new type, you have to edit the
   source code for all of the operations in the interface to add cases for
   the new type. The remaining alternatives will remove this limitation.

2. Classless OOP.
   Values are records, operations are record fields.

   Now you can add new types to an algebra without modifying existing code.
   As long as the new types are designed with this algebra in mind, since
   values are records containing operation names. You can't retrofit an existing
   type to interface it to a new algebra without modifying the existing type's
   implementation. Next, we'll remove this limitation as well.

3. Clojure Protocols.
   A Clojure Protocol describes the interface to an algebra,
   with no implementation code relating to data type representations
   or operation implementations.

   Now you can retrofit an existing type to interface to a new algebra, without
   modifying the code for the existing type. As long as the algebra is
   single-sorted. Next, we'll remove this limitation.

4. Generic Functions/Multimethods.
   Like protocols, but supporting multi-sorted algebras. In the classic design
   from CLOS and Clojure, you no longer have a single entity that collects all
   of the operations in the algebra together, and which requires you to
   implement all of the operations at once. Is that a problem? Haskell type
   classes have this property.

   Note, you can't have two implementations of the same algebra for the same
   type. The next method removes this limitation.

5. Explicit Method Dictionaries.
   A generic algorithm is passed an additional argument, a method dictionary,
   which implements an algebra. Or, inspired by the SML module system,
   a set of generic algorithms are exported by a module which is parameterized
   by one or more algebras.

Protocols/Multimethods: Spooky Action at a Distance?
----------------------------------------------------
Is this technique compatible with pure functional programming?
Binding an implementation to an algebra looks like spooky action at a distance.
* Loading a new package can fail due to conflict with an earlier loaded package?
  (Or if not fail, then break an existing package due to monkey patching.)
* Side effects: can you construct an impure function?
* Defeats local reasoning: inspecting a value to determine what it is.
  Defeats code completion? What ops are available with this value?

### 1. Package Conflicts (Language Safety)
We must eliminate package conflicts. This is not safe, functional, or local.
A package can only bind an implementation of a type to a protocol or multimethod
if it defines either the type or the protocol. If recursive dependencies are
forbidden between packages, then the problem is solved.

It's important that the protocol binding mechanism does not allow you modify
the semantics of a "third party" namespace.

Your project may use packages that you aren't aware of, due to transitive
dependencies of the packages you directly dependent on. These "hidden" packages
can add additional constructors to protocols that you use, and can add
additional operations to constructors that you use. Can you accidently write
code that depends on a hidden dependency, and can your code break if that
hidden dependency goes away in a later package update? Maybe it's not a problem.
The additional constructors and additional operations exist in namespaces
that you aren't aware of and can't directly access from code, since you don't
directly include those hidden packages into your namespace. This safety property
follows from the prohibition on modifying semantics of third party namespaces.

### How does this look in Curv?
* Within a module,
  * You can define a branded protocol, and optionally implement some branded
    constructors (which can be from other modules) for that protocol.
  * You can define a branded constructor, and optionally implement some branded
    protocols (which can be from other modules) for that constructor.
  * Protocol definitions, constructor definitions, and implement definitions,
    are syntactically separate statements, order independent, but taken
    together can constitute a distributed definition.
* Suppose shape operations are generic functions. Then how do you construct
  an anonymous shape, how does `make_shape` work? Like Clojure's `reify`?
    fields
        field1 = val1;
        field2 = val2;
    implementing
        protocol1 (fun1 = impl1, ...)
    end
  returns a record that implements 1 or more protocols.
* This works with protocols. It's trickier to construct an anonymous instance
  of a type in a multi-sorted algebra. You'd have to say which type is
  anonymous, and name the renamining types. Maybe not worthwhile.

### 2. Side Effects?
My imitation of `reify` looks not so different from classless OOP.
I think it is pure.

What about the more general constructs? We could define a pretend semantics
that associates protocol implementations with either the constructor or
the protocol, depending on how the binding was defined. Runtime dispatch
would search both places. This makes everything into local definitions.
So no side effects.

### 3. Local Reasoning?
With the safety restrictions in place, I think this comes down to a question
of IDE support for examining and reasoning about values and their protocols.

------
A collection of Curv values, with different representations, implement the
same abstract interface. There are different implementations of the operations
in the abstract interface for each representation.
* The Shape interface is an example.
* There is conceptually a 'graphical value' interface, with different
  implementations for shapes, colours, etc.

There is a predicate that tests if a value implements an abstract interface.

If this feature solves the Expression Problem, then:
* You can add a new representation to an abstract interface without modifying
  existing code. Similar to: object-oriented programming, where the AI is an
  abstract class, and a 'new representation' is a subclass. (By contrast,
  in FP you would need to modify an algebraic type to add a new variant.)
* You can add new operations to the abstract interface without modifying
  existing code. Similar to: functional programming, where the all of the
  representations are contained in an algebraic data type T, and a new
  operation is simply a new function of T. (By contrast, in OOP you would
  need to modify the abstract class to add a new method.)

Interfaces
----------
An 'interface' is a branded record or function type. Inheritance is supported.
Record and function values are branded with the interfaces that they support.

A record interface is a set of named fields that any conforming record must
possess, plus constraints that specify the meanings of those fields. The
constraints can include type constraints, assertions, and axioms. An interface T
can inherit structure from super-interfaces. T can define additional fields, or
it can further constrain inherited fields.

A function interface specifies constraints on a function's domain and range.

As a special case, Callable is a primitive interface implemented by all
functions: it denotes a value that can be used on the left side of a function
call. Records that implement Callable must have a `call` field that is bound to
a Callable value.

Curv doesn't have a logic system for reasoning about and proving axioms.
Instead, the axioms are in the documentation. Conforming values are given
a 'brand' (or type tag) that certifies that the value conforms to the
interface (which includes upholding the axioms in the documention).

In abstract algebra, the only difference between a Magma and a Monoid is that
the monoid has additional axioms like associativity. Monoid <: Magma.
So that's an example of a situation where the set of field names alone
are not enough to distinguish two interfaces. It's another argument for adding
branding (branded records) to the language.

If I'm adding branded interfaces to Curv, I want to use this feature
consistently, rather than use a mishmash of structural and nominal interface
matching. Shape becomes a branded interface, so does Callable.

Protocols (Clojure)
-------------------
Clojure provides both interfaces (due to JVM compatibility) and protocols
(which it prefers). A protocol names a set of functions that implement an
abstract interface, and contains no implementation. A protocol can be
implemented for a specific type T, which overloads each of those functions
with an implementation for T. You can test if a value implements a protocol.

Protocols are extrinsic: you externally bind a protocol to an existing type.
This helps solve the Expression Problem. Protocols are the single-dispatch
case of generic functions (called multi-methods). They remind me of Haskell
type classes.

Protocol inheritance is *not* supported--it is considered bad, but why?
* Due to a problem of how various features interact with Java?
* Due to a misunderstanding: the idea that all inheritance is bad, not
  distinguishing interface from implementation inheritance? Eg, this statement:
  "Tying polymorphism to inheritance is bad: protocols free you from that".
* I can find complaints about this limitation, but no good explanation.

Using clojure's Reify, you can construct an object that implements a Protocol,
without creating a separate type. There is an analogy with Curv Interfaces,
which are used to construct anonymous records that satisfy an Interface.
* https://david-mcneil.com/post/1475458103/implementation-inheritance-in-clojure
  Use record composition operations in Clojure to construct a record (aka map),
  simulating whatever implementation inheritance patterns you like, then
  bind protocols to the record using Reify.

Does this feature fit into, or make sense, in Curv?
* If the Shape interface was a Protocol, then you'd be using
  `Shape.distance S` rather than `S.dist`. This would permit us to use
  shape fields for constructor parameters in parametric shapes. That's nice.
* Binding a protocol has the side effect of modifying a table associated with
  the protocol's functions. Two distinct packages can bind the same type to
  the same protocol, and you have a conflict. It reminds me of monkeypatching,
  although less risk of an actual conflict. Clojure apparently just exhibits
  undefined behaviour and the answer is "don't do that", even though the problem
  can be caused by transitive dependencies you aren't aware of. A proposed rule
  is don't do it unless you own the protocol or you own the type. Maybe
  enforce that rule to eliminate the possibility of conflict.

The Expression Problem
----------------------
The main attraction of protocols is in solving the expression problem.
What are the alternatives, and which alternative fits best into Curv?
* Typed Tagless Final Interpreters by O. Kiselyov
* Polymorphic Variants in OCaml and Reason

Traits
------
A trait is a record interface combined with default field values.
In Java, if you extend an existing interface with new fields, you break existing
client classes, which now need to add definitions for the new fields.
Java interfaces are being extended to traits: you can add a new field with a
default value without breaking existing clients.

`make_shape` provides default values for shape fields. Maybe Shape should be
a trait. Or maybe Shape is an interface and it is make_shape that supplies
default values and applies Shape branding. But, make_shape is a mixin, and
trait composition is order independent.

Design
------
I do not want to support inheritance, or any module composition calculus using
late binding of variable references among the module fragments that are being
combined. This injects too much complexity into the programming model.

Mixins are composed linearly; this severely restricts one’s ability to specify
the “glue code” that is necessary to adapt the mixins so that they fit together.
Trait composition is order independent. Let's try traits instead.

The prelude actually describes an interface type, maybe call that a protocol.
Traits add the feature of default values for module fields. Conflicts must be
resolved manually. Trait composition is a kind of module composition.
* And the reason I'm considering default field values is because `make_shape`
  provides default field values, and it's very convenient.

Classic traits do have late binding of fields. The 'default field values' can
refer to other fields; the references aren't resolved until all traits are
composed into a record type. I said I don't want late binding or inheritance.
So what do I want?

Previous Thoughts
-----------------
Operations on a trait:
* Record constructor: Take a record R. Return a copy of R, modified to contain
  all of the fields required by the trait.
  * Required fields with default values will be added if missing.
  * If a required field doesn't have a default, and it is missing, then raise
    a domain error.
  * Required fields with bad values will raise a domain error.
  * Unrecognized fields will pass through without change (these unrecognized
    fields belong to other types, not known to the mixin).
  * A brand is added to the record certifying that the required fields are
    present and have appropriate values.
* Record predicate. Test if a record implements the trait.

If T is a trait, then
* `T R` is the record constructor
* `T? R` is the record predicate.
* `is_trait T` is true.

Is there a way for a record constructor to 'inherit' from another record R
(inheriting R's fields *and* traits)?
* No. That would be OOP style inheritance, inheriting both implementation and
  interface from the same source. This is a part of OOP that is considered
  harmful. You should only inherit from interfaces, not concrete classes.

Where does a trait's brand come from?
* The naive design is that make_trait (or whatever it's called) is an
  impure function that creates a unique new brand as a side effect.
  * That violates the functional purity of Curv.
  * This kind of trait doesn't have a meaningful name, suitable for printing.
* A better plan is to use the Branded Value mechanism to create the brand.
  This implies: you construct an anonymous trait value, then you apply
  a brand to it when binding it to a branded record field.
    @name = make_trait(...);
    f x = @make_trait(...);
  `make_trait` constructs an unbranded trait value. This is orthogonal design:
  the binding construct is orthogonal to the constructor. A benefit is that
  you can use abstraction mechanisms to compute the trait value.
  *Maybe* trait values are useful outside this context, but I don't know.
* Provide a special field binding construct for defining branded traits.
  There are no anonymous traits. This matches how most GP languages work.
    `trait <id> <opt-param-seq> = <trait-spec>`
  where <trait-spec> is *not* an expression. There's no abstraction over
  trait-specs, but this syntax has explicit provision for defining a function
  that constructs a trait.

How is a record trait specified?
* As a user-supplied function that maps a record onto a record.
  * If there are super-traits, they are buried inside the function and not
    accessible.
  * If multiple traits are applied to a record, they must be fully ordered,
    since there's no internal structure and no restrictions on what the
    function can do.
* Use a declarative DSL syntax. It's more structured and declarative.
  make_trait (super_traits...) {fields and assertions}
  Eg,
    @Shape = make_trait () {
        is_2d = false;
        is_3d = false;
        assert(is_2d || is_3d);
        bbox :: is_bbox3 = [[-inf,-inf,-inf],[inf,inf,inf]];
        colour p = sRGB[.8, .8, .5];
        distance :: is_func;
    }
  We can specify that the set of supertraits is unordered.
  Can two supertraits specify the same field?
  * Are unrelated fields with the same name simply merged?
  * Or do we require diamond inheritance in this case, where a given field
    name is ultimately derived from a single trait.
  If two supertraits provide a default value for the same field, then the
  base trait must also provide a default for that field.

How is a function trait specified?

Module Composition
------------------
Design a set of module composition operators.
Incomplete module fragments can be composed to create modules.
If a fragment is branded, then modules built from it will advertise the brand.

Module fragments typically support:
* Incomplete fields, with a name and possibly a type, but no value.
* Late binding: within a field definition, references to other fields are not
  bound until all of the fragments are composed into a module.

Two styles of module composition:
* Mixins. Are composed linearly: fields from later mixins override earlier of
  same name. Late binding via self & super reference. It's single inheritance
  semantics. This is the Jigsaw `override` operator (non-commutative).
* Traits. Conflicts must be resolved explicitly, by overriding in the base.
  Composition is commutative (unlike mixins). Is Jigsaw `merge` operator.

Mixin composition is a source of complexity, due to order dependence.
Late binding is a source of complexity, due to the way that it complects the
two module fragments being composed. These two sources of complexity account
for the complexity of object-oriented class inheritance. The campaign against
the complexity of OOP offers alternatives: composition, not inheritance.
Rust has traits, instead of class inheritance.

But, if I don't want the complexity of inheritance/late binding/self reference,
then I don't want module composition. I instead want 'protocols', which are
branded module types (which enforce that a module has a particular set of
fields).

(This comes from Simple Made Easy, where "inheritance" is part of the
"complexity toolkit", and "protocols" are part of the "simplicity toolkit".)

Module Composition Research
---------------------------
* Mixins (Gilad Bracha). Mixins are composed linearly, fields from later
  mixins override earlier of same name. There is self & super reference.
  It's single inheritance semantics.
  * jsonnet.org
* Traits. Conflicts must be resolved explicitly, by overriding in the base.
  Composition is commutative (unlike mixins).
* Jigsaw, Gilad Bracha
  * A module is a set of definitions and declarations. The latter has a name
    and type but no value, and if present the module is abstract.
  * `merge` combines modules. Duplicate definitions is an error.
    Duplicate declarations are combined. Associative & commutative.
  * `override(M1,M2)`: in a conflict, M2 has precedence.
  * `M rename a to b`, distributes over `override`
  * `M restrict a` converts definition to declaration.
  * ... and a whole lot more
* Units: Cool Modules for HOT Languages
  * A module fragment is called a Program Unit, or Unit.

2003 Traits paper: http://scg.unibe.ch/archive/papers/Scha03aTraits.pdf
Contrasts Trait composition with Mixin inheritance.
Mixins are composed linearly; this severely restricts one’s ability to specify
the “glue code” that is necessary to adapt the mixins so that they fit together.

Gilad Bracha, Jigsaw, module composition operators.

Names for this concept
----------------------
* trait
* concept
* contract
* protocol (not like clojure protocols, which are extrinsic, not intrinsic)
* interface
* signature
