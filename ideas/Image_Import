Import a 2D image file
======================
TODO:
-----
* Source and Location
  * A PNG file is now considered a "source file", and hence can be named
    in a stack trace item. Two cases:
     1. Just print the file name:
           At file "foo.png"
        Eg, an error in the `dist` or `colour` members of the shape record.
     2. Print filename and byte offset+length, when reporting an error while
        parsing the image file.
    These are the two cases for a Location that references a PNG file.
  * Generalize the Source class so that it can denote a PNG file, and
    contain the pathname, without containing the raw file data.
    * An instance of the base class Source may contain a pathname
      and no file contents.
  * Maybe `Image_Source` contains the pixel array, instead of `Image_Data`.

* `curv foo.png` imports foo.png, converts to value, displays or exports it.
        curv::Shared<curv::Script> script;
        if (expr) {
            script = curv::make<CString_Script>("", filename);
        } else {
            script = curv::make<curv::File_Script>(
                curv::make_string(filename), curv::Context{});
        }

        curv::Program prog{*script, sys};
        prog.compile();
        auto value = prog.eval();

        if (exporter) {
            exporter->call(value, prog, eparams, ofile);
            ofile.commit();
        } else {
            curv::geom::Shape_Program shape{prog};
            if (shape.recognize(value)) {
                print_shape(shape);
                curv::geom::viewer::Viewer viewer;
                viewer.set_shape(shape);
                viewer.run();
            } else {
                std::cout << value << "\n";
            }
        }
  This code requires a Program and a Value. How do we construct the Program?
  * How is the Program used?
     * Shape_Program shape{prog}; shape.recognize(value)
       * init nub_ from nub_phrase(prog.phrase_)
         * nub_ is used by At_Program.
       * init system_ from prog.system_
     * At_Program cx{prog}

* import_png constructs a shape, one initially not recognized by the Viewer.
  * An image value is just a Record.
  * The image data is loaded immediately (for now) into an Image_Data object,
    which is referenced by field values in the Record.
  * field values:
    * is_2d: true
    * is_3d: false
    * bbox: ...
    * dist: just a centred rectangle. Needs call and gl_call variants.
      class Image_Dist.
    * colour: class Image_Colour. `call` does bilinear interpolation and
      converts sRGB to linear. `gl_call` adds Image_Data to the GL_Compiler
      image list, references a uniform sampler2d.
    * call: class Image_Call. Later.
    * data: DEFERRED.

* Image_Data is an abstract list value. DEFERRED.
  Internally, it is a 2D array of 8bit*3 sRGB values.
  Externally, the sRGB values appear to be linear RGB vec3 values.
  * Virtualize the List interface using Abstract_List, use that in evaluator.
    libcurv/list.h still defines List, libcurv/alist.h defines Abstract_List.
  * All of my vectorized operators that work on Lists, will now work on
    Abstract_List, which is a performance hit. list[i] will be much slower.
    * Or, Curv supports multiple array data types for efficiency, distinguished
      using an enum. Look at other dynamically typed tensor languages.
      Multiple cell types (Value, sRGB24, ...). Efficient tensor type.
  * For consistency, rename Function and Structure to Abstract_Function and
    Abstract_Record in afunction.h and arecord.h.
  * Maybe Abstract_Function is superclass of Abstract_List, Abstract_Record,
    and String. Call_Expr just uses virtual call() method.
  * Get rid of ' operator (for simplicity of refactoring).

* Lazy image loading. DEFERRED.
  We preserve the file path and the context in the Image_Data object,
  and delay loading the image data until needed, which might not happen at all,
  or not until the Viewer runs. The context value is preserved by converting it
  to a Durable_Context, the only subclass of Context which is heap allocable.

Intro
-----
Use cases:
* RGB image, which is converted to:
  * a rectangular shape with a colour field
* Monochrome image, which is converted to:
  * an intensity field
  * a distance field
* RGBA is not supported, for now.

Let's focus on RGB images.

File types? Start with PNG.

When we import an image and convert it to a shape, there is no natural way
to determine the pixel size or image size in Curv coordinates. So we need to
use an arbitrary convention, or the user needs to explicitly state the image
size or pixel size.

According to the Package proposal, an image file 'foo.png' is imported using:
  `file "foo.png"` -- old syntax
  `file.foo` -- new syntax
This returns a Curv image value, encoded using the 7 types.

Possible requirements for image values:
* Easy to convert an image to a shape, with minimal syntax.
* Can explicitly specify the pixel or image size in Curv coordinates, when
  converting to a shape.
* Direct access to RGB pixel array, as a rank 3 tensor.

Here is a possible API for image values:
* img {psize: pixel_size} => shape
* img {xsize: image_width} => shape
* img {ysize: image_height} => shape
* img {size: (xd,yd)} => shape
* img.data => RGB pixel array as a rank 3 tensor
* IF an image value is a shape with an arbitrary default size,
  THEN `curv foo.png` will display an image.
  * If 'img' is a shape and 'img{xsize:2}' is a shape, then is img a prototype
    or parametric record? I will say yes.
  * What is this "arbitrary default size"? If the image is square, it should
    be 2x2. If non-square, then the smallest size that fully covers a
    unit circle, just like the regular polygons.

Eg, `file.my_icon {ysize: 2}`.

What happens to the colour field outside the image boundary?
I think {border_colour: black} would be a good default. Eg, if you offset
an image, you'll get a black border which is visible against the default
white backdrop.

If I provide control over the full colour field, it makes the most sense in the
context of creating an infinite texture from the image.

OpenGL provides several kinds of wrapping (note texture coordinates between 0
and 1 are inside the image):
* GL_REPEAT: The integer part of the coordinate will be ignored
  and a repeating pattern is formed. This is what glslViewer uses.
* GL_MIRRORED_REPEAT: The texture will also be repeated, but it will be
  mirrored when the integer part of the coordinate is odd.
* GL_CLAMP_TO_EDGE: The coordinate will simply be clamped between 0 and 1.
  Visually, this seems almost useless.
* GL_CLAMP_TO_BORDER: The coordinates that fall outside the range will be
  given a specified border color.
These can be specified independently for each coordinate.

So, maybe add an optional `texture` parameter to the image argument record,
which converts the image to an infinite texture.
* `texture: {repeat:}`
* `texture: {mirrored_repeat:}`
* `texture: {border_colour: colour}`
[Not in initial prototype.]

OpenGL allows two texture objects to share the same image data,
but with different 'wrap' options (see above). So it would be possible to
implement the wrapping options using OpenGL.

OpenGL also provides different 'filtering' options, for how interpolation
occurs for non-integer coordinates. The main options are 'nearest' and
'linear', the latter being bilinear interpolation. And then there is mipmapping.
I'll just use bilinear interpolation.

OpenGL doc: https://open.gl/textures

How does 'file.my_icon' print? Is it a term? I'll say yes.

Image Values
------------
curv::Image is what `file "foo.png"` returns.
It is a record with shape fields, plus `call` and `data`.
To satisfy the fields, we'll need Image_Call, Image_Data, Image_Dist,
Image_Colour. Plus Image_Data_Row.

Image is a subclass of Structure (rename as Abstract_Record).
Image_Data is a subclass of Abstract_List (new class).

The actual pixel data is stored in an Image_Data object, and the other Image
classes contain a Shared pointer to an Image_Data:
  Filesystem::path path_; // absolute pathname of image file
  // pixel data: RGB triples, 8 bits per channel, sRGB encoding.
  // lazy loading.
  int width_;
  int height_;
  const char* pixels_; // nullptr if not loaded.
  GLuint texture_id_; // lazy. 0 if not bound?

Multiple Viewer Windows
-----------------------
If there are multiple viewer windows, then in which OpenGL context are these
texture ids bound?
* Initially, a shape program can be displayed in only a single viewer.
  Image values cannot be shared between viewers. This means we can only have
  one viewer per console/editor pair, with no sharing between pairs.
  (And no central file cache, either.)
  Which means, only one viewer in the current design.
* Ultimately, we will need an invisible "system" context which owns all
  of the textures, and the viewer contexts will be children of the system
  context. This will allow for a central image cache, so that each image is
  loaded only once. Now I can add a 'view shape' action which is like 'print',
  but opens a viewer window.

GLSL Code
---------
An image is represented by a uniform variable of type `sampler2D`.
Eg, `uniform sampler2D image1`. If I use the shadertoy naming convention,
the names will be "iChannel$i" for i >= 0.

These samplers are referenced in calls to GLSL texture lookup functions.
    my_vec4 = texture(iChannel0, my_vec2)

The `texture` function requires implicit derivatives. "Non-uniform control flow"
violates the implicit-derivative requirement (and leads to undefined results,
not a compile time error). I don't think this can occur right now in Curv,
but it could be a problem in the future.

The GL compiler will traverse the shape value to generate code.
During this traversal, it produces several outputs:
 * A code string containing the main body of GLSL.
 * An image list, stored in the GL_Compiler.
   Each time an Image is found (that contributes to the final result), it is
   assigned a sequential integer ID and appended to the image list.
 
The Image list is used by:
* The GL compiler (converted to a list of sampler2D declarations, which is
  prepended to the main code body).
* The JIT compiler emits C++ code containing pathnames of images to load
  into memory.
* The Viewer loads each image into the GPU and defines uniform sampler2D
  variables for each image.

Viewer
------
The Viewer must load images into the GPU and make these images available
as sampler uniforms in the fragment shader. The Shape_Program contains the
image array.

Viewer::set_shape(Shape_Program&) must be used to set a new shape.
Get rid of set_frag(). Either set_shape() copies data from the program,
or the program is passed as unique_ptr<Shape_Program>.

Shape_Program shape{program};
b = shape.recognize(value);

Compiler/Evaluator
------------------
During compilation and/or evaluation, we need to construct the image array
and put it somewhere so it can be referenced by the Shape_Program.

Image file references are compile time constants (in the current design).
So, we'll construct the image array at compile time. The Analyzer will store
them in a Program structure accessed from the Environ.

If one program references another using `file`, then there is actually a
tree of Program objects. All of the image files will need to be considated
in the root Program, once the root Program has completed analysis.

`file("image_path.png")` -- or whatever the syntax -- results in a curv::Image
object, which contains the image file pathname, the image data (lazily loaded),
and an ID number, which is filled in by the GL compiler.

Evaluator
---------
We need the ability to evaluate image colour functions in the CPU as well:
* In the interpreter.
* In C++ JIT compiler output. How is the image data referenced?
  It will be reloaded from the original image files.
  (It could be inserted into the C++ code as C array data, but this is slower.)
