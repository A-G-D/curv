loc!func1!func2
---------------
struct Mutate_Action : public Operation
{
    struct XForm {
        // A call_phrase of the form `loc!f1!f2!...!fn`.
        Shared<const Phrase> call_phrase_;
        // The expression form of the 'fn' phrase from above.
        Shared<const Operation> func_expr_;
    };
    Unique<const Locative> locative_;
    std::vector<XForm> transformers_; // in the order f1, f2, ...
    Mutate_Action(
        Shared<const Phrase> syn,
        Shared<const Operation> loc,
        std::vector<XForm> tx)
    :
        Operation(move(syn)),
        locative_(move(loc)),
        transformers_(move(tx))
    {}
    void exec(Frame&, Executor&) const override;
};
Shared<Operation> Mutate_Phrase::analyse(Environ&, Interp) const
{
}
void Mutate_Action::exec(Frame& fm, Executor&) const
{
    locative_->mutate(fm, [&](Value val) -> Value {
        for (auto& tx : transformers_) {
            auto func = tx.func_expr_->eval(fm);
            val = call_func(func, val, tx.call_phrase_, fm);
        }
        return val;
    });
}
void Local_Locative::mutate(Frame& fm, std::function<Value(Value)> func) const
{
    fm[slot_] = func(fm[slot_]);
}
void Indexed_Locative::mutate(Frame& fm, std::function<Value(Value)> func) const
{
    base_->mutate(fm, [&](Value tree) -> Value {
        At_Phrase cx(*syntax_, fm);
        Value index = index_->eval(fm);
        Value elems = tree_fetch(tree, index, cx);
        elems = func(elems);
        return tree_amend(tree, index, elems, cx);
    });
}

### SC Compiler
How to compile compound locatives into GLSL code.
Two phases: analyse Locative, generate typed SC_Locative (IR node).
Then use SC_Locative to emit one or more assignment statements, given an
SC_Value.

### Assignment, in interpreter
* class Reference
* Reference Locative::getref(Frame&)
* indexed locative class.
* There is just one Assign_Action which contains a Locative.
    ref = loc_->getref(fr);
    newval = expr_->eval(fr);
    ref->store(newval);
* kinds of locatives:
    Locative -- abstract interface, getref(fr)
    Local_Locative -- denotes a frame slot
    Indexed_Locative -- Local_Locative + index expr
    List_Pattern_Locative -- zero or more Locative
    Record_Pattern_Locative -- zero or more Locative
* kinds of Reference:
    Reference -- abstract interface, fetch() and store(val)
    Local_Reference -- Value* slot
    Indexed_Reference -- Value* slot, Value index
    List_Pattern_Reference
    Record_Pattern_Reference
* efficiency of fetch-modify-store:
    curval = ref->fetch(cx);
    newval = f(curval);
    ref->store(newval,cx);
  using Indexed_Reference:
    fetch()
      curval = base_->fetch()
      return tree_fetch(curval, index_)
    store(n)
      curval = base_->fetch()
      newval = tree_amend(curval, index_, n)
      base_->store(newval)
    We fetch curval twice.
* alternative design. Locative::store(val) and Locative::modify(f).
  No Locative::fetch(). No Reference values.
  Doesn't work, Indexed_Locative::modify still needs separate fetch and store
  for its base_?

loc!func1!func2
  Phrase repr:
    Mutate_Phrase(loc,bangtok,func) -- nested
    subclass of Call_Phrase
  Op repr:
    Mutate_Action
      Locative locative_
      Expr index_ -- or null
      [callphrase,funcexpr]* transformers_
  calling a func:
    What callphrase to use? Use the original Mutate_Phrase created by parser.
    Each element of transformers_ is a [callphrase,funcexpr] pair.
  analysis:
    Instead of a locative_ and an index_, wouldn't it be better to
    encapsulate an indexed locative in one value? Why hasn't this been done?
    It's because we want to evaluate an indexed locative into a runtime
    representation that has fetch and store operations, and this repr doesn't
    exist yet.
    * Call it a Reference. The purpose of Reference objects is (1) abstraction
      and polymorphism, and (2) to pay the cost of evaluating a locative once,
      when multiple operations (normally 2) will be performed on it, at the
      cost of allocating an object. The use case is fetch, modify, store.
    * Maybe Locative::fetch_modify_store(transformer, frame)?
      Fewer allocations? To implement 'x +:= y' requires allocating (`+` y).
      To implement 'x!f!g!h' requires allocating 'compose[f,g,h]', which
      loses the intermediate Call_Phrases for x!f, x!f!g.
    * Is either form more efficient to compile? I dunno.
    I will implement Reference.

> void
> Mutate_Action::exec(Frame& fr, Executor&) const
> {
>     Value index;
>     if (index_) index = index_->eval(fr);
>     for (auto t : transforms_) {
>         Value f = t->eval(fr);
>         if (index) {
>         } else {
>             Value val = locative_->fetch(fr);
>             Value newval = call(f, val, fr);
>             locative_->store(fr, newval);
>         }
>     }
> }
void Mutate_Action::exec(Frame& fr, Executor&) const
    auto ref = locative_->getref(fr);
    for (auto t : transforms_)
        Value f = t->eval(fr);
        Value val = ref->fetch();
        Value newval = call_func(f, val, fr);
        ref->store(newval);

--------------
TODO:
* `without symbolList record`

Not Urgent:
* Array mapping (smap/dmap)
  * 'phase' accepts only a vec2 argument.
  * libcurv Smap and Smap2 replaces Prim framework.

-----
Binary_Array_Op::call() use Fail

which in turn invokes Prim::unbox_left() and unbox_right(), which may not
have the proper API (they have a Context arg but not a Fail arg).

What about these unbox functions? The API needs to be redesigned, what
should it be?

At present, unbox has 3 return statii: true, false, abort.
The abort option is rarely used, and amapped functions typically fault
with a "domain error" message, rather than a specific message like "not
a boolean".

Two options (behaviour of unbox):
1. No Context argument. 2 return statii: true, false.
   Fault messages from an amapped function are "domain error".
2. Fail, Context arguments. Returns:
    * True if argument has correct type.
    * Fail/Fault (with a precise error message) if argument has <= correct rank
      and incorrect type. Where 'fail' means return false (unless I change the
      result type to a ternary).
    * False if argument has > correct rank or is empty list.

Option 2 gives the precise error messages of the Failure proposal.

Option 3 (closer to the `amap` proposal):
 * Replace all of the unbox functions with a rank ordinal (unary),
   or two rank ordinals (binary).
      Prim::left_rank
      Prim::right_rank
 * Prim::call() now takes boxed Values instead of unboxed values,
   and fails/faults on a bad argument.
 * Arguments with the wrong rank will not be passed to Prim::call().

Option 2 or 3? Criteria:
 * code size and complexity (cost of adding new prims, maintenance, testing)
 * performance
 * how is `amap` implemented?

It's like the difference between these two amap designs:
 (a) amap F
     F is a ranked function, and fails if the argument has the wrong rank.
     amap fails is F is not ranked.
 (b) amap rank_metadata F
     amap only calls F with arguments of the appropriate rank, as specified
     by the rank metadata.
BUT: in the general case, you do need the ability to take an existing amapped
function, and amap it again using a higher rank. (Nested amap.) In this case,
design (a) doesn't work unless there is an additional combinator that applies
a rank to an existing function. Right now, I don't see how this additional
combinator provides any benefit, beyond constructing the amap argument.

So how about option 3?

C++ amap
--------
amap_unary<Rank, Prim> maps a Prim structure with a static call() function
(and other stuff) to another compatible Prim structure. It is nestable.

A Prim contains
    Value call(Value, Fail, const At_Syntax&)
    SC_Value sc_call(SC_Value, const SC_At_Syntax&)
    static constexpr char name[]

amap_unary::call(val, fl, cx)
    auto list = deeper_than_rank<Prim::rank>(val);
    if (list == nullptr)
        return Prim::call(val, fl, cx);
    else
        auto result = List::make(list->count());
        for (i in 0..<list.count)
            TRY_DEF(r, call(list[i], fl, cx));
            result[i] = r;
        return result

The current design provides helper classes that perform type checking,
and these helpers can be added as an optional extra to this amap design.
The helpers are class combinators (templates) that are applied to a
typed Prim, rather than inherited as a superclass. Using them is optional.

### Performance Considerations?
In the very first implementation of vectorized arithmetic, I had the insight
that with NaN boxing, it's efficient to apply the arithmetic operation first
on the raw NaN boxed floats, then switch to the general algorithm if the
result is NaN. (This trick didn't quite work for the 'max' operation, which
isn't normally NaN preserving.)

Can I reproduce this trick in the amap design? The 'happy path' code needs to be
added at the beginning of amap_unary::call. If the Prim has a special attribute,
then we use a constexpr if to add the happy path code (C++ 17). This 'special
attribute' is a 'numeric_call' function with a 'double val' parameter.
 * Test if a struct has a named member?
   SFINAE template hacking:
   https://stackoverflow.com/questions/257288/templated-check-for-the-existence-of-a-class-member-function

    if constexpr (has_numeric_call<Prim>::value) {
        double r = Prim::numeric_call(a.to_num_or_nan());
        if (r == r) return {r};
    }

Instead of always allocating a result vector, reuse the input list if it
has usecount 1. To be effective, this requires using move semantics
throughout the interpreter, which must be enabled using a compiler
optimization.
