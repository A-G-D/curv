## TODO: Language Changes

* lib
* std
* a[i] := item, i is an integer
* remove a'b
* function/record equivalence
  * primitive functions have a 'call' field, support 'fields' and 'defined'
    and 'f.call' and 'include' and '...'.
  * 'is_record f' is true
  * 'is_fun r' is true if r is a record with a call field.
    is_fun x = defined(x.call);
* compose -- function composition. Short form is 'co'?
  x >> compose[f,g,h] means x>>f>>g>>h ?
  The function returned by compose reports a pattern match failure if any
  of the constituent functions reports a pattern match failure. This is
  important for match and for cast patterns.
* any, all

## Ideas Under Development

### Patterns

New Pattern Types:
* '<pattern> if <condition>' -- pattern guard. The pattern is matched,
  variables are bound, then the condition is evaluated over the bound variables,
  and the match fails if the condition is false.
  * The 'phrase abstraction' design pattern asks if the syntax for this should
    actually be 'if (condition) pattern'? But the C if syntax is
    counterintuitive because the pattern binds variables in the condition.
  * Also, should we have 'statement if condition'?
* 'pat1 && pat2' -- the same value matches both patterns.
  * bound variables are disjoint between pat1 and pat2.
  * Idiom: 'id && pat' is like 'id@pat' in Haskell.
* 'pat1 || pat2' -- the value matches either pat1 or pat2.
  * pat1 and pat2 define identical sets of bound variables.
  * Useful when simulating a switch statement (one case matching 2 values).
  * [x,y] || [x,y,_==0]
  * Rust, F# use 'pat1|pat2' -- looks nice in switch.
* 'cast >> pat'
  * If V is the value being matched, then we evaluate `cast V`: if cast's
    parameter pattern fails, the match fails. Otherwise, the result of `cast V`
    becomes the new value that is matched against `pat`.
  * A cast is a function that maps values onto a particular type, and is
    idempotent for members of that type. This feature implements implicit
    conversions to a type.
  * S.P.Jones uses the term 'transformational pattern' (pat!fun), and shows
    that this is a way to reconcile pattern matching with data abstraction.
    The cast fun transforms an ADT to a pattern matchable value.
  * This wants to be a right-associative operator, but >> is left-associative.
  * Is 'cast1 >> (cast2 >> pat)' the same as 'compose[cast1,cast2] >> pat'?
    Only if the result of compose reports a pattern match failure if any
    of the constituent functions have a pattern match failure.
* Variations of predicate patterns:
  * 'pat == expr', 'pat != expr', 'pat < expr', ... -- relational op predicates
  * 'pat `elem` listexpr' -- range patterns, like 'x `elem` 1..10'.
  * Many languages have constant and range patterns, eg 42 and 1..10 are
    patterns, which works well in the 'switch statement' use case. But:
    * Conflicts with name abstraction, creates ambiguity.
      Is 'true' a constant pattern or an identifier pattern?
    * Conflicts with field_generator ::= "string":expr|pattern:expr

"Pattern Guards and Transformational Patterns", Simon Peyton Jones

Filtered For Loop:
Haskell: for (pattern in list) ..., list elements not matching pattern
are skipped. Convenient in some cases, hides coding errors in others.
Suppose we don't have 'for' patterns, then you need to simulate them,
and there are 2 cases (fail or skip on pattern match failure):
  for (x in list) let (a,b) = x in ...  -- fail on pattern match fail
  for (x in list) ...x>>match[(a,b)->[...], _->[]] -- skip on pattern fail
So, if both cases are equally useful, then skip on fail is the one that's
harder to simulate--so should it be the default?
Or maybe pattern guarded statements should be easier to write.

Pattern Guarded Statements:
  try (a,b) = x in stmt -- execute stmt if match succeeds, bind x in stmt.
  if (x matches (a,b)) stmt
We want the ability to AND together a chain of pattern and condition guards.

Guarded Expressions.
Haskell guarded equations:
filter p []                 = []
filter p (y:ys) | p y       = y : filter p ys
                | otherwise = filter p ys
A function parameter pattern can be guarded by a multi-branch conditional
whose failure counts as a failure of pattern matching in the original function.
* In Haskell 2010, each branch can have a comma-separated list of qualifiers;
  each qualifier is a pattern match or a boolean expression.
* A 'guarded expression' is an expression that either yields a value or fails
  due to pattern match failure. There's syntax for using a guarded expression
  as the body of a function, such that failure of the guarded expression
  consistutes a pattern match failure in the function call.
* In APL Direct Functions, a function body is a sequentially executed list
  of statements. Each statement is: a definition, a one-arm conditional
  expression (if condition, return this value), or an expression (return this
  value).

Guarded Expression Proposal:
* A 'guarded expression' is an expression that either yields a value or fails
  due to pattern match failure.
* If the body of a function is a guarded expression GE, then pattern
  match failure of the GE is pattern match failure of the function.
* A guarded expression comprises sequentially executed statements:
  * A one-arm conditional expression. If the condition succeeds, the expression
    is the result, otherwise proceed to next statement.
    * The 'condition' is a series of qualifiers: pattern matches expression,
      boolean expression. The former binds names in subsequent qualifiers
      and in the result.
    * This feature can be expressed using two statements that are nestable,
      and which in turn can be nested with `let` and `do`:
      * if (condition) statement
      * try (pattern = expression) statement
  * An unconditional expression, which yields the result.
  * Falling off the end of the statement list is a pattern match failure.
  * Optionally, we add the imperative sublanguage: sequential variable
    definitions, assignments, while loop, the action language.
  * Without the imperative sublanguage, this closely resembles `match`.
  * S.P.Jones gives an example of a nested guarded expression.
    Eg, if(c)guarded_expr or try(p=e)guarded_expr.
    A conditional GE fails if the GE fails.
* Possible GE syntax: list ::= 'case' list

### Unicode Strings
A string is a sequence of characters, but what is a character in Unicode?
 0. Legal code points.
    The NUL character is disallowed. Surrogate and noncharacter code points
    are disallowed.
 1. Character boundaries.
    Maybe a character is a code point. It's simple.
    In Swift, a character is an "extended grapheme cluster". Eg, an emoji
    flag character consists of two code points, but counts as one character.
    The 'string.count' method iterates over the string.
    The Unicode standard says that a "user perceived character"
    is most closely approximated by an "extended grapheme cluster".
    (Any closer approximation is locale-dependent.)
    http://unicode.org/reports/tr29/#Grapheme_Cluster_Boundaries
    Regular expressions should ideally use EGCs as character boundaries.
    If I can find an open source library that implements these semantics,
    may I should use it.
     * https://github.com/michaelnmmeyer/grapheme
       It uses Ragel, which is similar to re2c.
       Ragel is in the Ubuntu Universe.
 2. When are two characters equal? If they have the same sequence of code
    points, or if they normalize to the same sequence? (How does Swift do it?)
    If two grapheme clusters are guaranteed (by the Unicode standard)
    to have the same printed representation, then they compare equal?
    * If two code point sequences are canonically equivalent, then they should
      test equal, independent of locale.
      https://en.wikipedia.org/wiki/Unicode_equivalence
    * Is there open source for comparing two unicode strings and determining
      canonical equivalence?
    * Is it easier or harder to pre-normalize all Curv strings and then
      test byte-level equality? If I support Unicode in symbols, then those
      should probably be normalized, for efficiency reasons.
 3. String Concatenation, Legal EGCs.
    Suppose S1 and S2 are strings.
    Is it guaranteed that count(strcat(S1,S2)) == count S1 + count S2?
    What if S1 is a latin base character, and S2 is a latin accent
    combining character? Should S2 even be treated as a legal character string?
    Suppose S1 and S2 are normalized. Is strcat(S1,S2) guaranteed to be
    normalized?

### Libraries.
* `lib` is a record for accessing library files in /usr/local/lib/curv.
  `lib.foo` loads /usr/local/lib/curv/foo.curv.
  * `use lib.foo`

### Casts/Coercions (advanced feature)
* A *coercion* is an idempotent function that:
  * maps a member of a type onto itself,
  * optionally converts non-member values to members (a type conversion),
  * throws an exception for argument values that aren't members of the type or
    convertible to the type.
  Every function has a parameter pattern.
  For a coercion, the parameter pattern match fails for values that are clearly
  not a member of the type. For values that are considered corrupted instances
  of the type, the pattern match succeeds but an assertion fails.
* Curv has built-in coercion functions for primitive types.
  Null, Bool, Num, String, List, Record, Function.
* `coercion pat` is a pattern that matches `pat`. The `coercion` function
  is first applied to the value to be matched, then the resulting value
  is matched by `pat`. Now changed to `cast >> pat`.
* Example:
    fact = match [
        0 -> 1;
        Nat n -> n * fact(n - 1);
    ];
* "is(val,coercion)" or "val `is` coercion" returns true if the coercion's
  pattern matches, returns false if the pattern match fails,
  and aborts with an error if the coercion body aborts.
  Not necessary, we have type predicates for this.
  Cast functions are not a replacement for predicates.

Name of this concept:
* cast, coercion, classifier, type function
* `is`, `isa`, x `matches` f
  (belongs to a type, is in the domain of a function)

Can we replace is_shape and make_shape with Shape?
* That's a semantic change: is_shape requires all 5 fields, while make_shape
  only requires `dist` and one of `is_2d` or `is_3d`.
* The constructors for a type should not always be coercions.
* Use `Shape` for is_shape and `Shape.make` for make_shape.
    Shape = {
        call (r && defined(r.dist) && defined(r.colour) && defined(r.bbox)
                && defined(r.is_2d) && defined(r.is_3d))
        =
            do  assert(r.dist `isa` Fun);
                assert(r.colour `isa` Fun);
                assert(r.bbox `isa` BBox);
                assert(r.is_2d || r.is_3d);
            in r;
        make r = 
    };

The best parts of the coercion proposal are:
* You can declare the type of a parameter.
* A parameter match aborts with a meaningful message if the argument value
  structurally matches the type, but is corrupted. This is better than falling
  off the end of the match.

However, I am suspicious of the value of implicit conversions. I did some
experiments. Liberal type conversions (like converting '2' to '(2,2)' in Vec2)
can make the Shape library API confusing and accident-prone. The same problem
has been reported for other programming languages, from Javascript back to PL/I.
Coercion functions are more complicated to write, and the concept is a bit more
difficult to understand than predicate functions.

Let's instead use predicate patterns. A type predicate aborts if the argument
value structurally matches the type, but is corrupted (data structure
invariants fail).

### Type Classes:
We can define a 'type class' as a record containing a 'call' function
(a type predicate), plus constructors (eg 'make')
and operations on type instances. Eg,
    BBox = {
        call = ...;
        union = ...;
        intersection = ...;
    };
If multiple classes implement the same protocol, then we have the effect of
Haskell type classes. A class needs to be passed as an explicit argument.
    f T (T x) = ...

### Tensors
Indexing:
* a[i] := item, i is an integer
* s.key := item
* remove a'b ?

List Slices:
`a[i..<count a]` is inconvenient, repeats `a`. Fix?
* Maybe a[...] is a special syntactic context, in which:
  * a[..j] and a[i..] are special abbreviations.
  * `end` is bound to index of final element, like MatLab.
    So a[i..end]
* Maybe `i..` is an infinite range value, can be used to slice a list.
  Short for `i..inf`. `count(i..)==inf`.
* `take n list` and `drop n list` for +ve and -ve n.
* Can't support Python negative indexes (-1 indexes the last element)
  because [0..count a - 1] is a list of the indexes of a, even if a is empty,
  meaning that [0..-1] denotes [].

Multidimensional array slicing a[i,j,k].
`a` is rectangular array of dimension `d`, or tree of max depth `d`.
Currently: Non-final indexes must be integers. Final index can be a tree.
Works on trees.

List Slice Assignment:
* `v[[X,Z]] := v2`, similar to GLSL vector swizzle assignment.
  Source and destination lists have the same count.
* a[i..j] := list. In a range slice assignment,
  source and destination lists can have different counts.
* Generalized `a[list1] := list2`. list1 and list2 can have different counts.
  If list1 is shorter, extra elements at end of list2 are appended to final
  element indexed by list1.
  If list1 is longer, extra elements indexed by list1 are deleted.

Multidimensional Array Slice Assignment `a[i,j,k] := x`.
`a` is rectangular array of dimension `d`, or tree of max depth `d`.
* All indices are integers. Easy, works for trees.
* `a` is an array, all indices are arrays. As in APL.
  What happens if the same element is indexed twice? What's the new value?

### Vectorized boolean operations:
* vectorize `bit`
* Vectorized relations are:
  * infix operators:
    * <' <=' >' >=' ==' !='
    * .< .<= .> .>= .== .!= (Julia)
  * or n-ary functions, infixed using backtick:
    * less, greater, equal, less_or_equal, greater_or_equal, not_equal (FLUENT)
    * lt, gt, eq, le, ge, ne (TERSE, Matlab)
    * less, greater, equal, not_less, not_greater, not_equal
    * If f'g is function composition,
      then we can write not'less, not'greater, not'equal.
    * Hamcrest: greater_than, greater_than_or_equal_to,
                less_than, less_than_or_equal_to
                equal_to
    * Mathematica: equal, unequal, greater, greater_equal, less, less_equal
    * eg, a `greater` b, a `gt` b, a `greater_than` b
          a `less_equal` b, a `less_or_equal` b, a `not_greater` b, a `le` b
          a `less_than_or_equal_to` b
    * unified table of alternative spellings:
      * eq, equal, equal_to
      * ne, not_equal, unequal, not_equal_to
      * lt, less, less_than
      * le, less_equal, less_or_equal, less_than_or_equal_to
* `not` is vectorized version of `!`.
* `all` and `any` are vectorized boolean monoids for && and ||.
  * Name is consistent with GLSL,R,Julia,Python,Matlab.
  * Use some(pred)list, every(pred)list, name consistent with Javascript.
  * Haskell uses "and". Eg, a `any` b  vs  a `and` b
* ifelse(cond,thenval,elseval)
* Rationale: vectorized boolean ops have different names than unvectorized ones.
  * x==y compares vectors and returns bool, unlike xs=='ys/xs `equal` ys.
  * a&&b short circuits if a==false, but all(a,b) must evaluate b if a==false
    to implement broadcasting.
  * ifelse(b,c,a) must evaluate all 3 arguments if b is an array.
  * The unvectorized relations are guaranteed to return Bool, or fail,
    which is appropriate for the most common use case, which is to construct
    an argument for if, &&, ||, which require a Bool argument.
* Many languages represent boolean values as the numbers 0 and 1.
  In an array language, an array of booleans represented as 0 and 1
  is a useful representation, you can do arithmetic on it.
  In Curv, booleans are not numbers, but you can convert between the two
  representations using vectorized operations. Eg,
  * enbool(i) = [false,true]'i;
  * debool(b) = ifelse(b, 1, 0);
  Or:
  * tobool(i), frombool(b)
  Or:
  * idiom: i != 0, or i !=' 0
  * bit(b) = ifelse(b, 1, 0);

### Design by contract:
* postconditions:
  ensure pred val = do assert(pred val) in val;
  sort x =
    ensure sorted <<
    <body of sort function>;
* parameter preconditions:
  * (predicate x) -> body -- implemented
  * (x >= 0) -> body
  * (x >= 0 && x <= 1) -> body
* We want the ability to add arbitrary predicates to a pattern match.
  See 'match', 'coercion' and 'guard expressions' for use cases.
  `pat && condition` seems like a promising syntax.

### Debug actions:
* print_timing(string,expr), returns value of expr
* `exec(expr)`: evaluate an expression for its side effects, discard results.
  `_=expr` could be an alternative (see _ pattern), but might be optimized away.
  * exec(file "unit_test.curv");
  * exec(print_timing("msg",expr));
* `enter_debugger`, aka `debug`
* assert_error(errorMessageString, expression)

### Generalized Definitions:
* id = expr
* ( definition )
* def1; def2; def3
* simple patterns: `[x,y,z] = expr` etc.
* patterns with default values: `{x=42,y,z} = expr` etc.
  * How are the default value expressions analysed in a recursive scope?
    Recursion is outlawed. No references to other bindings in the same
    recursive binding partition.
* `use (constant in std namespace)`. Eg, use(file "foo.curv").
* `use {module}`
  Could be used to embed sequential bindings in a recursive scope, or v.v.?
  Could be useful in abstract evaluation where the {module} argument is
  unwrapped during abstract evaluation? Dunno.
  `use {module} where (localDefinitions)`? Information hiding, in lieu of
  private module members.
* `if (cond) (a=foo;b=bar) else (a=bar;b=foo)`
* `def where bindings`, let bindings in def`.
  Could be used to embed sequential bindings in a recursive scope, or v.v.
  Information hiding, in lieu of private module members.

### Lexical:
* unicode operators (needs re2c or Ragel)
    90° == 90*deg
    ≤ ≥ ≠
    ¬a == !a
    a·b == dot(a,b)
    a×b == a*b or maybe cross(a,b)
    a÷b
    √a
    a∧b == a&&b
    a∨b == a||b
    x→x+1   ==   x->x+1
    for (i ∈ 1..10)
    π == pi
    τ == tau
    ∞ == inf
    x↑y = x^y
    “foo” == "foo"  -- note, resistant to systems that autocorrect "" to “”
    g∘f == compose[g,f]
    1.0₁₀3 == 1.0e3 -- not seriously, though.
* Use _ as digit separator in numerals.
* Support ' (primes) in identifiers (like Haskell)? Nope, ' is needed elsewhere.
* Support `foo` quoted identifiers? Nope, ` already used for infix operators.
  Compatibility with GUI interfaces that display
  parameter names as GUI labels, JSON object keys.
* 'foo' quoted identifiers and x `f` y infix notation?

### OpenSCAD2 prototype oriented programming?
* Model parameters and shape are bundled into one value.
* Simple syntax for customizing a subset of model parameters, generating
  a new shape.
* The BOM feature: can extract model parameters from a model script,
  generate JSON output.
* Language support for using a GUI to tweak model parameters?
  `param bindings in shape`. But what does this construct? Are the parameters
  represented in the value that is constructed, or does the GUI interpret
  the syntax?
* CSG trees: output a CSG tree as JSON, read a CSG tree to reconstruct model.
  Shapes contain the name of their constructor, and their constructor
  arguments. (Implemented using a proposed 'constructor' feature.)

### Data Abstraction:
* Wm. Cook distinguishes two kinds of data abstraction: CLU style "ADT"s,
  and Smalltalk style "objects". The untyped lambda calculus is enough to
  do object oriented data abstraction. Record literals make it easier.
  http://www.cs.utexas.edu/~wcook/Drafts/2009/essay.pdf
* I don't need extra features to support CLU-style information hiding.
  It's not that important.
* I do need the ability to define shape "subclasses" that obey specialized
  protocols. Eg, symmetrical polyhedra that support the Conway operators.
  I can already do this: a shape protocol is defined informally as a set of
  shape fields and axioms. I don't need explicit classes or inheritance
  or other explicit language mechanisms.
* This approach uses "duck typing". A shape just has to obey the protocol,
  it doesn't have to explicitly declare that it obeys the protocol.
* Do I need a language mechanism that allows a shape or record to declare what
  protocols it supports, in support of a cheap protocol testing predicate?
  (Like `val isa protocol`.)
  * I like the idea. I want it for type declarations, Design By Contract, etc.
    And for overloading positional arguments based on type, rather than relying
    on parameter labels as in Smalltalk & Swift.
  * But it's complicated to design, implement, document.
  * Cook observes that Smalltalk programmers generally don't need or use such
    a feature. So it's likely I don't need this in Curv.
  * Cook observes a tradeoff between flexibility (duck typing) and type
    correctness (explicit typing). Academics prefer type correctness.
    Some dynamic language communities (eg Smalltalk) prefer flexibility.
* Thus: In 1.0, support labelled parameters, de-emphasize explicit typing
  and type predicates.
* By this logic, I can get rid of the built-in Shape type.
  There are now 7 types: the 6 JSON types, plus functions.
  A shape is a record that implements `is_2d`,`is_3d`,`dist`,`bbox`,`colour`.
  This is the "shape protocol". `make_shape` is implemented in Curv, defines
  missing fields using default values, aborts if a bad field is detected.
* Do I need "inheritance"? Ability to override data or function fields
  while maintaining self-reference in function fields. That's needed for OOP.
  Right now, I'll say no.

  Note if you build an object-like data abstraction using records, with
  fields representing instance variables, and fields representing methods
  that reference the instance variables (function closures that contain
  separate copies of said instance variables), then reassigning an instance
  variable will leave the methods out of sync with the instance variables.

  So use a programming idiom that avoids this. To update an instance variable,
  you actually transform a value into another related value, using a function
  that invokes the constructor with a transformed copy of the instance variables
  as arguments.

### Function/Record Equivalence.
* Using {call x = f x}, a record can behave like a function.
* For symmetry, a function behaves like a record with a single `call` field.
* What about `is_fun`?
  * Get rid of `is_fun`. `is_record` is true for primitive functions.
    Test for `call` field in a record to identify a function.
  * Or, `is_fun` is true for records that contain a `call` field,
    and `is_record` is true for primitive functions. So Fun is a subtype of
    Record.
    * Then, what about lists and strings, which also support function call
      syntax? Are List and String subtypes of Fun? If so, then `count` cannot
      be polymorphic across Record and List. We maybe need to use
      `count(fields record)` to count the fields in a record.

### Haskell algebraic type constructors
  data Maybe a = Nothing | Just a
Constructors for this type, in Curv:
  {Nothing:}     -- or `null`, to be idiomatic.
  {Just: 42}
New feature:
  The expression {foo:} is an abbreviation for {foo: true}.
  The pattern {foo:} matches the record {foo:true}, binds no parameters.
  Can't specify a default value for a field pattern like `foo:`.
Eg,
  align{x:{centre:}, z:{above:0}}
Eg,
  make_shape{is_3d:, ...}

### Literal Patterns (deprecated)
  fact 0 = 1;
  fact (is_int n && n > 0) = n * fact(n - 1);
New feature:
  * numerals, string literals, `null`, `true` and `false` are now patterns.
  * Now, any JSON expression is a literal pattern.
  * `null`, `true` and `false` are now reserved words.
Low priority:
  * You can use `(x == literal)` instead of `literal`.
Deprecated:
  * The syntax of a binder phrase is `string|pattern : expr`.
    Literal string patterns are incompatible.

### User defined infix operators.
* a `postfixExpr` b  ===>  postfixExpr(a,b)
* examples:
    a `mod` m  ===>  mod(a,m)
    v1 `dot` v2  ===>  dot(v1,v2)
    v1 `cross` v2  ===>  cross(v1,v2)
    a `union` b ===> union(a,b)
    a `smooth_union .5` b  ==> smooth_union .5 (a,b)
* `...` is right associative, same precedence as >>
* So you can use "`fun` arg" as an element in a geometry pipeline

smooth_intersection .1 (
    gyroid >> shell .2 >> lipschitz 2 >> bend (tau*12),
    torus (tau*4, tau*2),
) >> colour (hsv2rgb (1/3, 1, .5))

gyroid
  >> shell .2
  >> lipshitz 2
  >> bend (tau*12)
  `smooth_intersection .1` torus(tau*4, tau*2)
  >> colour (hsv2rgb (1/3, 1, .5))

Maybe `foo` also works as a low precedence prefix operator.
(`foo` b) a <==> (a `foo` b) <==> foo(a,b).
So you can also write:

gyroid
  >> shell .2
  >> lipshitz 2
  >> bend (tau*12)
  >> `smooth_intersection .1` torus(tau*4, tau*2)
  >> colour (hsv2rgb (1/3, 1, .5))

map (`sum` 1) list

### Indentation As Syntax
let:
  x=1
  y=2
in x+y

Also, `do:`, `where:`, `[:` and `{:`.

### Versioned External Packages
Like Rust Cargo. An external library has a GIT url and a version.
Eg, file{repo:"https://github.com/doug-moen/laser-curv.git", version:"1.0"}

Directory syntax for `file`.

### Guarded Expression Sequence
Loosely inspired by guards in Haskell 2010 and in APL Direct Functions.
 1) First version. A sequence of statements of these kinds:
    * a sequential definition,
    * an action,
    * a guarded expression (condition=>expr) -- if the condition is true,
      return the expression,
    * an unguarded expression (return its value).
 2) Second version, based on Haskell 2010, incorporating pattern matching.
    A guarded expression is generalized, so you have a list of guards.
    Each guard is either a condition, or pat<-expr. The latter evaluates expr
    and succeeds if the pattern matches the result (binding names as a side
    effect of successful pattern match).
 3) A syntax for generalized guarded expressions:
      if (guard1 && guard2 && ...) expr
    or
      expr if guard1 && guard2 && ...
    where guard is an expression or 'expr matches pattern'.
    Maybe 'pattern = expr' is a guard, but it's error prone (x==a vs x=a).

### Action/Generator Abstraction
Support tail recursion as a form of iteration in list/record generators.
This could mean:
* New syntax: a recursive loop construct whose body can be an action or
  generator. Previously designed as `loop` (aka Scheme named let).
* Lambda abstraction for actions, list/record generators.

### Function Composition
Long-form function composition is `compose[f,g]`.
Maybe I want an abbreviated infix form?
    f'g
This looks nice if each function in the composition is an identifier.
The syntax makes sense if I create a library of standard function names
that are intended to be composed in this way.

Transformations can be composed.

Compose a colour map with an intensity field.
There are a bunch of standard named colour maps and intensity fields.
eg, rainbow'linear_gradient
    rainbow'radial_gradient
    greyscale'cosine_gradient

### Add shebang comments, `#!` to end of line
